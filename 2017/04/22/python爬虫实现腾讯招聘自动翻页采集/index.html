<!DOCTYPE html>
<html lang="zh-CN">

  
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="utf-8">
  <meta name="author" content="sparsematrix@163.com">
  
  

  <title>Pythonçˆ¬è™«å®ç°è…¾è®¯æ‹›è˜è‡ªåŠ¨ç¿»é¡µé‡‡é›† | æ¯å¤©ï¼Œé‡åˆ°æ›´å¥½çš„ä½ </title>

  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  
    <meta name="keywords" content="Python,å¤§æ•°æ®,Python,">
  

  <script>
    console.log('\n%c Hexo-theme-bmw v4.0 ' + '%c ğŸ‰ https://github.com/dongyuanxin/theme-bmw ğŸ‰\n' + '\n%c View demo online ' + '%c ğŸ” https://godbmw.com/ ğŸ”  \n' , 'color: #fadfa3; background: #030307; padding:3px 0;', '', 'color: #fadfa3; background: #030307; padding:3px 0;', '');
  </script>

  

  

  
    <link rel="icon" href="/images/favicon.png">
    <link rel="apple-touch-icon" href="/images/favicon.ico">
  

  <link href="https://cdn.bootcss.com/fancybox/3.5.2/jquery.fancybox.min.css" rel="stylesheet">
  <link rel="stylesheet" href="/css/base.css">
<link rel="stylesheet" href="/icon/iconfont.css">
<link rel="stylesheet" href="/css/github-markdown.css">
<link rel="stylesheet" href="/css/highlight.css">

  <script src="/js/util.js"></script>
<script src="/js/valine.min.js"></script>

  

  
    <link href="https://cdn.bootcss.com/aplayer/1.10.1/APlayer.min.css" rel="stylesheet">
    <script src="https://cdn.bootcss.com/aplayer/1.10.1/APlayer.min.js" async></script>
  

  
    <link href="https://cdn.bootcss.com/social-share.js/1.0.16/css/share.min.css" rel="stylesheet">
  

  <script src="//cdn.bootcss.com/jquery/3.3.1/jquery.min.js" async></script>

  
    <script src="//cdn.jsdelivr.net/npm/leancloud-storage@3.11.0/dist/av-min.js"></script>
  

</head>


  <body>

    

    <div id="app">

      <div class="header-wrap">
  <header>
    <div class="site-brand">
      <div class="site-title">
        <!-- <a href="/">MatrixSparse</a> -->
        <img alt="logo" class="antd-pro-layouts-user-layout-logo" src="/images/favicon.png" style="width: 200px;height: 40px;margin: 10px 0 0 5px;">
      </div>
    </div>
    <nav class="site-navigation">
      <ul class="nav-menu">
      
        <li class="nav-item" data-path="/">
          
            <a href="/" target="_self">
              ä¸»é¡µ
            </a>
          
        </li>
      
        <li class="nav-item" data-path="/archives/">
          
            <a href="/archives/" target="_self">
              å½’æ¡£
            </a>
          
        </li>
      
        <li class="nav-item" data-path="/categories/">
          
            <a href="/categories/" target="_self">
              åˆ†ç±»
            </a>
          
        </li>
      
        <li class="nav-item" data-path="/tags/">
          
            <a href="/tags/" target="_self">
              æ ‡ç­¾
            </a>
          
        </li>
      
        <li class="nav-item" data-path="">
          
            <a href="javascript:void(0);" v-else="">åšå®¢åœ°å€</a>
            <ul class="nav-menu--dropdown">
              
                <li>
                  <a href="https://blog.csdn.net/qq_25371579" target="_blank">
                    CSDN
                  </a>
                </li>
              
                <li>
                  <a href="https://github.com/matrixsparse" target="_blank">
                    Github
                  </a>
                </li>
              
                <li>
                  <a href="https://matrixsparse.github.io/" target="_blank">
                    Github Page
                  </a>
                </li>
              
            </ul>
          
        </li>
      
      </ul>
    </nav>
    <i class="iconfont icon-menu"></i>
  </header>
</div>

<script>
  let links = document.querySelectorAll('.nav-item');
  for(let link of links){
    let childrenLink = link.querySelector('ul');
    link.addEventListener('mouseenter', () => {
      if(childrenLink) {
        childrenLink.className = "nav-menu--dropdown active";
      }
    })
    link.addEventListener('mouseleave', () => {
      if(childrenLink) {
        childrenLink.className = "nav-menu--dropdown";
      }
    })
  }
  let rootRealPath = getRealPath(window.location.pathname, true);
  for(let link of links) {
    let linkPath = link.getAttribute("data-path");
    if(linkPath && getRealPath(linkPath, true) === rootRealPath) {
      link.className = "nav-item hover";
    }
  }

  let iconMenu = document.querySelector("i.iconfont.icon-menu"),
    iconMenuClicked = false;
  let navDOM = document.querySelector("nav.site-navigation");
  iconMenu.addEventListener("click", () => {
    iconMenuClicked
      ? navDOM.className = "site-navigation active"
      : navDOM.className = "site-navigation";
    iconMenuClicked = !iconMenuClicked;
  })
</script>


      








<div class="container post-index">

  

<div class="post">
  <h1 class="article-title">
    <span>Pythonçˆ¬è™«å®ç°è…¾è®¯æ‹›è˜è‡ªåŠ¨ç¿»é¡µé‡‡é›†</span>
  </h1>
  <div class="article-top-meta">
    <span>
      å‘å¸ƒ : 
      2017-04-22
    </span>
    
      <span>
        åˆ†ç±» : 
          <a href="/categories/Python/">
            Python
          </a>
      </span>
    
    
      <span>
        æµè§ˆ : <span class="article-timer" data-identity="pythonçˆ¬è™«å®ç°è…¾è®¯æ‹›è˜è‡ªåŠ¨ç¿»é¡µé‡‡é›†"></span>
      </span>
    
  </div>

  

  <div class="article-content">
    <div class="markdown-body">
      <h2 id="spider"><a href="#spider" class="headerlink" title="spider"></a>spider</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">Spiderç±»å®šä¹‰äº†å¦‚ä½•çˆ¬å–æŸä¸ª(æˆ–æŸäº›)ç½‘ç«™ã€‚</span><br><span class="line">åŒ…æ‹¬äº†çˆ¬å–çš„åŠ¨ä½œ(ä¾‹å¦‚:æ˜¯å¦è·Ÿè¿›é“¾æ¥)ä»¥åŠå¦‚ä½•ä»ç½‘é¡µçš„å†…å®¹ä¸­æå–ç»“æ„åŒ–æ•°æ®(çˆ¬å–item)ã€‚</span><br><span class="line">æ¢å¥è¯è¯´ï¼ŒSpiderå°±æ˜¯æ‚¨å®šä¹‰çˆ¬å–çš„åŠ¨ä½œåŠåˆ†ææŸä¸ªç½‘é¡µ(æˆ–è€…æ˜¯æœ‰äº›ç½‘é¡µ)çš„åœ°æ–¹ã€‚</span><br><span class="line"></span><br><span class="line">class scrapy.Spideræ˜¯æœ€åŸºæœ¬çš„ç±»ï¼Œæ‰€æœ‰ç¼–å†™çš„çˆ¬è™«å¿…é¡»ç»§æ‰¿è¿™ä¸ªç±»ã€‚</span><br><span class="line"></span><br><span class="line">ä¸»è¦ç”¨åˆ°çš„å‡½æ•°åŠè°ƒç”¨é¡ºåºä¸ºï¼š</span><br><span class="line"></span><br><span class="line">__init__() : åˆå§‹åŒ–çˆ¬è™«åå­—å’Œstart_urlsåˆ—è¡¨</span><br><span class="line">start_requests() è°ƒç”¨make_requests_from url():ç”ŸæˆRequestså¯¹è±¡äº¤ç»™Scrapyä¸‹è½½å¹¶è¿”å›response</span><br><span class="line">parse() : è§£æresponseï¼Œå¹¶è¿”å›Itemæˆ–Requestsï¼ˆéœ€æŒ‡å®šå›è°ƒå‡½æ•°ï¼‰ã€‚Itemä¼ ç»™Item piplineæŒä¹…åŒ– ï¼Œ è€ŒRequestsäº¤ç”±Scrapyä¸‹è½½ï¼Œå¹¶ç”±æŒ‡å®šçš„å›è°ƒå‡½æ•°å¤„ç†ï¼ˆé»˜è®¤parse())ï¼Œä¸€ç›´è¿›è¡Œå¾ªç¯ï¼Œç›´åˆ°å¤„ç†å®Œæ‰€æœ‰çš„æ•°æ®ä¸ºæ­¢ã€‚</span><br></pre></td></tr></table></figure>
<blockquote>
<p>æºç </p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#æ‰€æœ‰çˆ¬è™«çš„åŸºç±»ï¼Œç”¨æˆ·å®šä¹‰çš„çˆ¬è™«å¿…é¡»ä»è¿™ä¸ªç±»ç»§æ‰¿</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Spider</span><span class="params">(object_ref)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">#å®šä¹‰spideråå­—çš„å­—ç¬¦ä¸²(string)ã€‚spiderçš„åå­—å®šä¹‰äº†Scrapyå¦‚ä½•å®šä½(å¹¶åˆå§‹åŒ–)spiderï¼Œæ‰€ä»¥å…¶å¿…é¡»æ˜¯å”¯ä¸€çš„ã€‚</span></span><br><span class="line">    <span class="comment">#nameæ˜¯spideræœ€é‡è¦çš„å±æ€§ï¼Œè€Œä¸”æ˜¯å¿…é¡»çš„ã€‚</span></span><br><span class="line">    <span class="comment">#ä¸€èˆ¬åšæ³•æ˜¯ä»¥è¯¥ç½‘ç«™(domain)(åŠ æˆ–ä¸åŠ  åç¼€ )æ¥å‘½åspiderã€‚ ä¾‹å¦‚ï¼Œå¦‚æœspiderçˆ¬å– mywebsite.com ï¼Œè¯¥spideré€šå¸¸ä¼šè¢«å‘½åä¸º mywebsite</span></span><br><span class="line">    name = <span class="keyword">None</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">#åˆå§‹åŒ–ï¼Œæå–çˆ¬è™«åå­—ï¼Œstart_ruls</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, name=None, **kwargs)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> name <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line">            self.name = name</span><br><span class="line">        <span class="comment"># å¦‚æœçˆ¬è™«æ²¡æœ‰åå­—ï¼Œä¸­æ–­åç»­æ“ä½œåˆ™æŠ¥é”™</span></span><br><span class="line">        <span class="keyword">elif</span> <span class="keyword">not</span> getattr(self, <span class="string">'name'</span>, <span class="keyword">None</span>):</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">"%s must have a name"</span> % type(self).__name__)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># python å¯¹è±¡æˆ–ç±»å‹é€šè¿‡å†…ç½®æˆå‘˜__dict__æ¥å­˜å‚¨æˆå‘˜ä¿¡æ¯</span></span><br><span class="line">        self.__dict__.update(kwargs)</span><br><span class="line"></span><br><span class="line">        <span class="comment">#URLåˆ—è¡¨ã€‚å½“æ²¡æœ‰æŒ‡å®šçš„URLæ—¶ï¼Œspiderå°†ä»è¯¥åˆ—è¡¨ä¸­å¼€å§‹è¿›è¡Œçˆ¬å–ã€‚ å› æ­¤ï¼Œç¬¬ä¸€ä¸ªè¢«è·å–åˆ°çš„é¡µé¢çš„URLå°†æ˜¯è¯¥åˆ—è¡¨ä¹‹ä¸€ã€‚ åç»­çš„URLå°†ä¼šä»è·å–åˆ°çš„æ•°æ®ä¸­æå–ã€‚</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> hasattr(self, <span class="string">'start_urls'</span>):</span><br><span class="line">            self.start_urls = []</span><br><span class="line"></span><br><span class="line">    <span class="comment"># æ‰“å°Scrapyæ‰§è¡Œåçš„logä¿¡æ¯</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">log</span><span class="params">(self, message, level=log.DEBUG, **kw)</span>:</span></span><br><span class="line">        log.msg(message, spider=self, level=level, **kw)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># åˆ¤æ–­å¯¹è±¡objectçš„å±æ€§æ˜¯å¦å­˜åœ¨ï¼Œä¸å­˜åœ¨åšæ–­è¨€å¤„ç†</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">set_crawler</span><span class="params">(self, crawler)</span>:</span></span><br><span class="line">        <span class="keyword">assert</span> <span class="keyword">not</span> hasattr(self, <span class="string">'_crawler'</span>), <span class="string">"Spider already bounded to %s"</span> % crawler</span><br><span class="line">        self._crawler = crawler</span><br><span class="line"></span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">crawler</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">assert</span> hasattr(self, <span class="string">'_crawler'</span>), <span class="string">"Spider not bounded to any crawler"</span></span><br><span class="line">        <span class="keyword">return</span> self._crawler</span><br><span class="line"></span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">settings</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.crawler.settings</span><br><span class="line"></span><br><span class="line">    <span class="comment">#è¯¥æ–¹æ³•å°†è¯»å–start_urlså†…çš„åœ°å€ï¼Œå¹¶ä¸ºæ¯ä¸€ä¸ªåœ°å€ç”Ÿæˆä¸€ä¸ªRequestå¯¹è±¡ï¼Œäº¤ç»™Scrapyä¸‹è½½å¹¶è¿”å›Response</span></span><br><span class="line">    <span class="comment">#è¯¥æ–¹æ³•ä»…è°ƒç”¨ä¸€æ¬¡</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">start_requests</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">for</span> url <span class="keyword">in</span> self.start_urls:</span><br><span class="line">            <span class="keyword">yield</span> self.make_requests_from_url(url)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#start_requests()ä¸­è°ƒç”¨ï¼Œå®é™…ç”ŸæˆRequestçš„å‡½æ•°ã€‚</span></span><br><span class="line">    <span class="comment">#Requestå¯¹è±¡é»˜è®¤çš„å›è°ƒå‡½æ•°ä¸ºparse()ï¼Œæäº¤çš„æ–¹å¼ä¸ºget</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">make_requests_from_url</span><span class="params">(self, url)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> Request(url, dont_filter=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#é»˜è®¤çš„Requestå¯¹è±¡å›è°ƒå‡½æ•°ï¼Œå¤„ç†è¿”å›çš„responseã€‚</span></span><br><span class="line">    <span class="comment">#ç”ŸæˆItemæˆ–è€…Requestå¯¹è±¡ã€‚ç”¨æˆ·å¿…é¡»å®ç°è¿™ä¸ªç±»</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        <span class="keyword">raise</span> NotImplementedError</span><br><span class="line"></span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">handles_request</span><span class="params">(cls, request)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> url_is_from_spider(request.url, cls)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__str__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> <span class="string">"&lt;%s %r at 0x%0x&gt;"</span> % (type(self).__name__, self.name, id(self))</span><br><span class="line"></span><br><span class="line">    __repr__ = __str__</span><br></pre></td></tr></table></figure>
<h3 id="ä¸»è¦å±æ€§å’Œæ–¹æ³•"><a href="#ä¸»è¦å±æ€§å’Œæ–¹æ³•" class="headerlink" title="ä¸»è¦å±æ€§å’Œæ–¹æ³•"></a>ä¸»è¦å±æ€§å’Œæ–¹æ³•</h3><blockquote>
<p>name</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">å®šä¹‰spideråå­—çš„å­—ç¬¦ä¸²ã€‚</span><br><span class="line"></span><br><span class="line">ä¾‹å¦‚ï¼Œå¦‚æœspiderçˆ¬å– mywebsite.com ï¼Œè¯¥spideré€šå¸¸ä¼šè¢«å‘½åä¸º mywebsite</span><br></pre></td></tr></table></figure>
<blockquote>
<p>allowed_domains</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">åŒ…å«äº†spiderå…è®¸çˆ¬å–çš„åŸŸå(domain)çš„åˆ—è¡¨ï¼Œå¯é€‰ã€‚</span><br></pre></td></tr></table></figure>
<blockquote>
<p>start_urls</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">åˆå§‹URLå…ƒç¥–/åˆ—è¡¨ã€‚å½“æ²¡æœ‰åˆ¶å®šç‰¹å®šçš„URLæ—¶ï¼Œspiderå°†ä»è¯¥åˆ—è¡¨ä¸­å¼€å§‹è¿›è¡Œçˆ¬å–ã€‚</span><br></pre></td></tr></table></figure>
<blockquote>
<p>start_requests(self)</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">è¯¥æ–¹æ³•å¿…é¡»è¿”å›ä¸€ä¸ªå¯è¿­ä»£å¯¹è±¡(iterable)ã€‚</span><br><span class="line">è¯¥å¯¹è±¡åŒ…å«äº†spiderç”¨äºçˆ¬å–ï¼ˆé»˜è®¤å®ç°æ˜¯ä½¿ç”¨ start_urls çš„urlï¼‰çš„ç¬¬ä¸€ä¸ªRequestã€‚</span><br><span class="line"></span><br><span class="line">å½“spiderå¯åŠ¨çˆ¬å–å¹¶ä¸”æœªæŒ‡å®šstart_urlsæ—¶ï¼Œè¯¥æ–¹æ³•è¢«è°ƒç”¨ã€‚</span><br></pre></td></tr></table></figure>
<blockquote>
<p>parse(self, response)</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">å½“è¯·æ±‚urlè¿”å›ç½‘é¡µæ²¡æœ‰æŒ‡å®šå›è°ƒå‡½æ•°æ—¶ï¼Œé»˜è®¤çš„Requestå¯¹è±¡å›è°ƒå‡½æ•°ã€‚</span><br><span class="line">ç”¨æ¥å¤„ç†ç½‘é¡µè¿”å›çš„responseï¼Œä»¥åŠç”ŸæˆItemæˆ–è€…Requestå¯¹è±¡ã€‚</span><br></pre></td></tr></table></figure>
<blockquote>
<p>log(self, message[, level, component])</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ä½¿ç”¨scrapy.log.msg()æ–¹æ³•è®°å½•(<span class="built_in">log</span>)messageã€‚</span><br></pre></td></tr></table></figure>
<h2 id="Pythonå®ç°æ•°æ®è‡ªåŠ¨ç¿»é¡µé‡‡é›†"><a href="#Pythonå®ç°æ•°æ®è‡ªåŠ¨ç¿»é¡µé‡‡é›†" class="headerlink" title="Pythonå®ç°æ•°æ®è‡ªåŠ¨ç¿»é¡µé‡‡é›†"></a>Pythonå®ç°æ•°æ®è‡ªåŠ¨ç¿»é¡µé‡‡é›†</h2><blockquote>
<p>æ–°å»ºScrapyé¡¹ç›®</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy startproject tencentspider</span><br></pre></td></tr></table></figure>
<p><img src="http://i1.piimg.com/581590/2b7f3e2fb871b5d7.png" alt="Markdown"></p>
<blockquote>
<p>åˆ›å»ºçˆ¬è™«</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy genspider tencent <span class="string">"tencent.com"</span></span><br></pre></td></tr></table></figure>
<p><img src="http://i1.piimg.com/581590/3994c11953cfbe74.png" alt="Markdown"></p>
<blockquote>
<p>ç¼–å†™items.py</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">è·å–èŒä½åç§°ã€è¯¦ç»†ä¿¡æ¯</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TencentspiderItem</span><span class="params">(scrapy.Item)</span>:</span></span><br><span class="line">    <span class="comment"># define the fields for your item here like:</span></span><br><span class="line">    name = scrapy.Field()</span><br><span class="line">    detailLink = scrapy.Field()</span><br><span class="line">    positionInfo = scrapy.Field()</span><br><span class="line">    peopleNumber = scrapy.Field()</span><br><span class="line">    workLocation = scrapy.Field()</span><br><span class="line">    publicTime = scrapy.Field()</span><br></pre></td></tr></table></figure>
<blockquote>
<p>ç¼–å†™tencent.pyæ–‡ä»¶</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">from</span> tencentspider.items <span class="keyword">import</span> TencentspiderItem</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TencentSpider</span><span class="params">(scrapy.Spider)</span>:</span></span><br><span class="line">    name = <span class="string">"tencent"</span></span><br><span class="line">    allowed_domains = [<span class="string">"hr.tencent.com"</span>]</span><br><span class="line">    start_urls = [<span class="string">'http://hr.tencent.com/position.php?&amp;start=0#a'</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        oddList = response.xpath(<span class="string">'//*[@class="odd"]'</span>)</span><br><span class="line">        evenList = response.xpath(<span class="string">'//*[@class="even"]'</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> odd,even <span class="keyword">in</span> zip(oddList, evenList):</span><br><span class="line">            odditem = TencentspiderItem()</span><br><span class="line">            evenitem = TencentspiderItem()</span><br><span class="line">            odditem[<span class="string">'name'</span>] = odd.xpath(<span class="string">'./td[1]/a/text()'</span>).extract()[<span class="number">0</span>]</span><br><span class="line">            odditem[<span class="string">'detailLink'</span>] = odd.xpath(<span class="string">'.//td[1]/a/@href'</span>).extract()[<span class="number">0</span>]</span><br><span class="line">            odditem[<span class="string">'positionInfo'</span>] = odd.xpath(<span class="string">'./td[2]/text()'</span>).extract()[<span class="number">0</span>]</span><br><span class="line">            odditem[<span class="string">'peopleNumber'</span>] = odd.xpath(<span class="string">'./td[3]/text()'</span>).extract()[<span class="number">0</span>]</span><br><span class="line">            odditem[<span class="string">'workLocation'</span>] = odd.xpath(<span class="string">'./td[4]/text()'</span>).extract()[<span class="number">0</span>]</span><br><span class="line">            odditem[<span class="string">'publicTime'</span>] = odd.xpath(<span class="string">'./td[5]/text()'</span>).extract()[<span class="number">0</span>]</span><br><span class="line">            evenitem[<span class="string">'name'</span>] = even.xpath(<span class="string">'./td[1]/a/text()'</span>).extract()[<span class="number">0</span>]</span><br><span class="line">            evenitem[<span class="string">'detailLink'</span>] = even.xpath(<span class="string">'.//td[1]/a/@href'</span>).extract()[<span class="number">0</span>]</span><br><span class="line">            evenitem[<span class="string">'positionInfo'</span>] = even.xpath(<span class="string">'./td[2]/text()'</span>).extract()[<span class="number">0</span>]</span><br><span class="line">            evenitem[<span class="string">'peopleNumber'</span>] = even.xpath(<span class="string">'./td[3]/text()'</span>).extract()[<span class="number">0</span>]</span><br><span class="line">            evenitem[<span class="string">'workLocation'</span>] = even.xpath(<span class="string">'./td[4]/text()'</span>).extract()[<span class="number">0</span>]</span><br><span class="line">            evenitem[<span class="string">'publicTime'</span>] = even.xpath(<span class="string">'./td[5]/text()'</span>).extract()[<span class="number">0</span>]</span><br><span class="line">            <span class="comment"># è®¾ç½®è‡ªåŠ¨ç¿»é¡µ</span></span><br><span class="line">            curpage = re.search(<span class="string">'(\d+)'</span>, response.url).group(<span class="number">1</span>)</span><br><span class="line">            page = int(curpage) + <span class="number">10</span></span><br><span class="line">            url = re.sub(<span class="string">'(\d+)'</span>, str(page), response.url)</span><br><span class="line">            <span class="comment"># å‘é€æ–°çš„urlè¯·æ±‚åŠ å…¥å¾…çˆ¬é˜Ÿåˆ—ï¼Œå¹¶è°ƒç”¨å›è°ƒå‡½æ•°self.parse</span></span><br><span class="line">            <span class="keyword">yield</span> scrapy.Request(url, callback=self.parse)</span><br><span class="line">            <span class="comment"># å°†è·å–çš„æ•°æ®äº¤ç»™pipeline</span></span><br><span class="line">            <span class="keyword">yield</span> odditem</span><br><span class="line">            <span class="keyword">yield</span> evenitem</span><br></pre></td></tr></table></figure>
<blockquote>
<p>ç¼–å†™pipeline.pyæ–‡ä»¶</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Define your item pipelines here</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Don't forget to add your pipeline to the ITEM_PIPELINES setting</span></span><br><span class="line"><span class="comment"># See: http://doc.scrapy.org/en/latest/topics/item-pipeline.html</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TencentspiderPipeline</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.file = open(<span class="string">'tencent.json'</span>, <span class="string">'wb'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span><span class="params">(self, item, spider)</span>:</span></span><br><span class="line">        content = json.dumps(dict(item), ensure_ascii=<span class="keyword">False</span>) + <span class="string">"\n"</span></span><br><span class="line">        self.file.write(bytes(content, encoding=<span class="string">'utf-8'</span>))</span><br><span class="line">        <span class="keyword">return</span> item</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">close_spider</span><span class="params">(self, spider)</span>:</span></span><br><span class="line">        self.file.close()</span><br></pre></td></tr></table></figure>
<blockquote>
<p>åœ¨setting.pyé‡Œè®¾ç½®ITEM_PIPELINES</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ITEM_PIPELINES = &#123;</span><br><span class="line">   <span class="string">'tencentspider.pipelines.TencentspiderPipeline'</span>: <span class="number">300</span>,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><img src="http://i4.buimg.com/581590/f3d1b7124064d119.png" alt="Markdown"></p>
<blockquote>
<p>æ‰§è¡Œçˆ¬è™«</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy crawl tencent</span><br></pre></td></tr></table></figure>
<p><img src="http://i4.buimg.com/581590/7d32b6a97b75d6c4.png" alt="Markdown"></p>
<blockquote>
<p> parse()æ–¹æ³•çš„å·¥ä½œæœºåˆ¶</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">1.å› ä¸ºä½¿ç”¨çš„yieldï¼Œè€Œä¸æ˜¯<span class="built_in">return</span>ã€‚parseå‡½æ•°å°†ä¼šè¢«å½“åšä¸€ä¸ªç”Ÿæˆå™¨ä½¿ç”¨ã€‚</span><br><span class="line">scrapyä¼šé€ä¸€è·å–parseæ–¹æ³•ä¸­ç”Ÿæˆçš„ç»“æœï¼Œå¹¶åˆ¤æ–­è¯¥ç»“æœæ˜¯ä¸€ä¸ªä»€ä¹ˆæ ·çš„ç±»å‹ï¼›</span><br><span class="line">2.å¦‚æœæ˜¯requeståˆ™åŠ å…¥çˆ¬å–é˜Ÿåˆ—ï¼Œå¦‚æœæ˜¯itemç±»å‹åˆ™ä½¿ç”¨pipelineå¤„ç†ï¼Œå…¶ä»–ç±»å‹åˆ™è¿”å›é”™è¯¯ä¿¡æ¯ã€‚</span><br><span class="line">3.scrapyå–åˆ°ç¬¬ä¸€éƒ¨åˆ†çš„requestä¸ä¼šç«‹é©¬å°±å»å‘é€è¿™ä¸ªrequestï¼Œåªæ˜¯æŠŠè¿™ä¸ªrequestæ”¾åˆ°é˜Ÿåˆ—é‡Œï¼Œç„¶åæ¥ç€ä»ç”Ÿæˆå™¨é‡Œè·å–ï¼›</span><br><span class="line">4.å–å°½ç¬¬ä¸€éƒ¨åˆ†çš„requestï¼Œç„¶åå†è·å–ç¬¬äºŒéƒ¨åˆ†çš„itemï¼Œå–åˆ°itemäº†ï¼Œå°±ä¼šæ”¾åˆ°å¯¹åº”çš„pipelineé‡Œå¤„ç†ï¼›</span><br><span class="line">5.parse()æ–¹æ³•ä½œä¸ºå›è°ƒå‡½æ•°(callback)èµ‹å€¼ç»™äº†Requestï¼ŒæŒ‡å®šparse()æ–¹æ³•æ¥å¤„ç†è¿™äº›è¯·æ±‚ scrapy.Request(url, callback=self.parse)</span><br><span class="line">6.Requestå¯¹è±¡ç»è¿‡è°ƒåº¦ï¼Œæ‰§è¡Œç”Ÿæˆscrapy.http.response()çš„å“åº”å¯¹è±¡ï¼Œå¹¶é€å›ç»™parse()æ–¹æ³•ï¼Œç›´åˆ°è°ƒåº¦å™¨ä¸­æ²¡æœ‰Requestï¼ˆé€’å½’çš„æ€è·¯ï¼‰</span><br><span class="line">7.å–å°½ä¹‹åï¼Œparse()å·¥ä½œç»“æŸï¼Œå¼•æ“å†æ ¹æ®é˜Ÿåˆ—å’Œpipelinesä¸­çš„å†…å®¹å»æ‰§è¡Œç›¸åº”çš„æ“ä½œï¼›</span><br><span class="line">8.ç¨‹åºåœ¨å–å¾—å„ä¸ªé¡µé¢çš„itemså‰ï¼Œä¼šå…ˆå¤„ç†å®Œä¹‹å‰æ‰€æœ‰çš„requesté˜Ÿåˆ—é‡Œçš„è¯·æ±‚ï¼Œç„¶åå†æå–itemsã€‚</span><br><span class="line">7.è¿™ä¸€åˆ‡çš„ä¸€åˆ‡ï¼ŒScrapyå¼•æ“å’Œè°ƒåº¦å™¨å°†è´Ÿè´£åˆ°åº•ã€‚</span><br></pre></td></tr></table></figure>
<h3 id="CrawlSpiders"><a href="#CrawlSpiders" class="headerlink" title="CrawlSpiders"></a>CrawlSpiders</h3><blockquote>
<p>åˆ›å»ºCrawlSpideræ¨¡æ¿</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy genspider -t crawl tencent tencent.com</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">class scrapy.spiders.CrawlSpider</span><br><span class="line"></span><br><span class="line">å®ƒæ˜¯Spiderçš„æ´¾ç”Ÿç±»ï¼ŒSpiderç±»çš„è®¾è®¡åŸåˆ™æ˜¯åªçˆ¬å–start_urlåˆ—è¡¨ä¸­çš„ç½‘é¡µï¼Œ</span><br><span class="line"></span><br><span class="line">è€ŒCrawlSpiderç±»å®šä¹‰äº†ä¸€äº›è§„åˆ™(rule)æ¥æä¾›è·Ÿè¿›linkçš„æ–¹ä¾¿çš„æœºåˆ¶ï¼Œ</span><br><span class="line"></span><br><span class="line">ä»çˆ¬å–çš„ç½‘é¡µä¸­è·å–linkå¹¶ç»§ç»­çˆ¬å–çš„å·¥ä½œæ›´é€‚åˆã€‚</span><br></pre></td></tr></table></figure>
<blockquote>
<p>æºç </p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CrawlSpider</span><span class="params">(Spider)</span>:</span></span><br><span class="line">    rules = ()</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, *a, **kw)</span>:</span></span><br><span class="line">        super(CrawlSpider, self).__init__(*a, **kw)</span><br><span class="line">        self._compile_rules()</span><br><span class="line"></span><br><span class="line">    <span class="comment">#é¦–å…ˆè°ƒç”¨parse()æ¥å¤„ç†start_urlsä¸­è¿”å›çš„responseå¯¹è±¡</span></span><br><span class="line">    <span class="comment">#parse()åˆ™å°†è¿™äº›responseå¯¹è±¡ä¼ é€’ç»™äº†_parse_response()å‡½æ•°å¤„ç†ï¼Œå¹¶è®¾ç½®å›è°ƒå‡½æ•°ä¸ºparse_start_url()</span></span><br><span class="line">    <span class="comment">#è®¾ç½®äº†è·Ÿè¿›æ ‡å¿—ä½True</span></span><br><span class="line">    <span class="comment">#parseå°†è¿”å›itemå’Œè·Ÿè¿›äº†çš„Requestå¯¹è±¡    </span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self._parse_response(response, self.parse_start_url, cb_kwargs=&#123;&#125;, follow=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#å¤„ç†start_urlä¸­è¿”å›çš„responseï¼Œéœ€è¦é‡å†™</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_start_url</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> []</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_results</span><span class="params">(self, response, results)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> results</span><br><span class="line"></span><br><span class="line">    <span class="comment">#ä»responseä¸­æŠ½å–ç¬¦åˆä»»ä¸€ç”¨æˆ·å®šä¹‰'è§„åˆ™'çš„é“¾æ¥ï¼Œå¹¶æ„é€ æˆResquestå¯¹è±¡è¿”å›</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_requests_to_follow</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> isinstance(response, HtmlResponse):</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        seen = set()</span><br><span class="line">        <span class="comment">#æŠ½å–ä¹‹å†…çš„æ‰€æœ‰é“¾æ¥ï¼Œåªè¦é€šè¿‡ä»»æ„ä¸€ä¸ª'è§„åˆ™'ï¼Œå³è¡¨ç¤ºåˆæ³•</span></span><br><span class="line">        <span class="keyword">for</span> n, rule <span class="keyword">in</span> enumerate(self._rules):</span><br><span class="line">            links = [l <span class="keyword">for</span> l <span class="keyword">in</span> rule.link_extractor.extract_links(response) <span class="keyword">if</span> l <span class="keyword">not</span> <span class="keyword">in</span> seen]</span><br><span class="line">            <span class="comment">#ä½¿ç”¨ç”¨æˆ·æŒ‡å®šçš„process_linkså¤„ç†æ¯ä¸ªè¿æ¥</span></span><br><span class="line">            <span class="keyword">if</span> links <span class="keyword">and</span> rule.process_links:</span><br><span class="line">                links = rule.process_links(links)</span><br><span class="line">            <span class="comment">#å°†é“¾æ¥åŠ å…¥seené›†åˆï¼Œä¸ºæ¯ä¸ªé“¾æ¥ç”ŸæˆRequestå¯¹è±¡ï¼Œå¹¶è®¾ç½®å›è°ƒå‡½æ•°ä¸º_repsonse_downloaded()</span></span><br><span class="line">            <span class="keyword">for</span> link <span class="keyword">in</span> links:</span><br><span class="line">                seen.add(link)</span><br><span class="line">                <span class="comment">#æ„é€ Requestå¯¹è±¡ï¼Œå¹¶å°†Ruleè§„åˆ™ä¸­å®šä¹‰çš„å›è°ƒå‡½æ•°ä½œä¸ºè¿™ä¸ªRequestå¯¹è±¡çš„å›è°ƒå‡½æ•°</span></span><br><span class="line">                r = Request(url=link.url, callback=self._response_downloaded)</span><br><span class="line">                r.meta.update(rule=n, link_text=link.text)</span><br><span class="line">                <span class="comment">#å¯¹æ¯ä¸ªRequestè°ƒç”¨process_request()å‡½æ•°ã€‚è¯¥å‡½æ•°é»˜è®¤ä¸ºindentifyï¼Œå³ä¸åšä»»ä½•å¤„ç†ï¼Œç›´æ¥è¿”å›è¯¥Request.</span></span><br><span class="line">                <span class="keyword">yield</span> rule.process_request(r)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#å¤„ç†é€šè¿‡ruleæå–å‡ºçš„è¿æ¥ï¼Œå¹¶è¿”å›itemä»¥åŠrequest</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_response_downloaded</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        rule = self._rules[response.meta[<span class="string">'rule'</span>]]</span><br><span class="line">        <span class="keyword">return</span> self._parse_response(response, rule.callback, rule.cb_kwargs, rule.follow)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#è§£æresponseå¯¹è±¡ï¼Œä¼šç”¨callbackè§£æå¤„ç†ä»–ï¼Œå¹¶è¿”å›requestæˆ–Itemå¯¹è±¡</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_parse_response</span><span class="params">(self, response, callback, cb_kwargs, follow=True)</span>:</span></span><br><span class="line">        <span class="comment">#é¦–å…ˆåˆ¤æ–­æ˜¯å¦è®¾ç½®äº†å›è°ƒå‡½æ•°ã€‚ï¼ˆè¯¥å›è°ƒå‡½æ•°å¯èƒ½æ˜¯ruleä¸­çš„è§£æå‡½æ•°ï¼Œä¹Ÿå¯èƒ½æ˜¯ parse_start_urlå‡½æ•°ï¼‰</span></span><br><span class="line">        <span class="comment">#å¦‚æœè®¾ç½®äº†å›è°ƒå‡½æ•°ï¼ˆparse_start_url()ï¼‰ï¼Œé‚£ä¹ˆé¦–å…ˆç”¨parse_start_url()å¤„ç†responseå¯¹è±¡ï¼Œ</span></span><br><span class="line">        <span class="comment">#ç„¶åå†äº¤ç»™process_resultså¤„ç†ã€‚è¿”å›cb_resçš„ä¸€ä¸ªåˆ—è¡¨</span></span><br><span class="line">        <span class="keyword">if</span> callback:</span><br><span class="line">            <span class="comment">#å¦‚æœæ˜¯parseè°ƒç”¨çš„ï¼Œåˆ™ä¼šè§£ææˆRequestå¯¹è±¡</span></span><br><span class="line">            <span class="comment">#å¦‚æœæ˜¯rule callbackï¼Œåˆ™ä¼šè§£ææˆItem</span></span><br><span class="line">            cb_res = callback(response, **cb_kwargs) <span class="keyword">or</span> ()</span><br><span class="line">            cb_res = self.process_results(response, cb_res)</span><br><span class="line">            <span class="keyword">for</span> requests_or_item <span class="keyword">in</span> iterate_spider_output(cb_res):</span><br><span class="line">                <span class="keyword">yield</span> requests_or_item</span><br><span class="line"></span><br><span class="line">        <span class="comment">#å¦‚æœéœ€è¦è·Ÿè¿›ï¼Œé‚£ä¹ˆä½¿ç”¨å®šä¹‰çš„Ruleè§„åˆ™æå–å¹¶è¿”å›è¿™äº›Requestå¯¹è±¡</span></span><br><span class="line">        <span class="keyword">if</span> follow <span class="keyword">and</span> self._follow_links:</span><br><span class="line">            <span class="comment">#è¿”å›æ¯ä¸ªRequestå¯¹è±¡</span></span><br><span class="line">            <span class="keyword">for</span> request_or_item <span class="keyword">in</span> self._requests_to_follow(response):</span><br><span class="line">                <span class="keyword">yield</span> request_or_item</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_compile_rules</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">get_method</span><span class="params">(method)</span>:</span></span><br><span class="line">            <span class="keyword">if</span> callable(method):</span><br><span class="line">                <span class="keyword">return</span> method</span><br><span class="line">            <span class="keyword">elif</span> isinstance(method, basestring):</span><br><span class="line">                <span class="keyword">return</span> getattr(self, method, <span class="keyword">None</span>)</span><br><span class="line"></span><br><span class="line">        self._rules = [copy.copy(r) <span class="keyword">for</span> r <span class="keyword">in</span> self.rules]</span><br><span class="line">        <span class="keyword">for</span> rule <span class="keyword">in</span> self._rules:</span><br><span class="line">            rule.callback = get_method(rule.callback)</span><br><span class="line">            rule.process_links = get_method(rule.process_links)</span><br><span class="line">            rule.process_request = get_method(rule.process_request)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">set_crawler</span><span class="params">(self, crawler)</span>:</span></span><br><span class="line">        super(CrawlSpider, self).set_crawler(crawler)</span><br><span class="line">        self._follow_links = crawler.settings.getbool(<span class="string">'CRAWLSPIDER_FOLLOW_LINKS'</span>, <span class="keyword">True</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CrawlSpiderç»§æ‰¿äºSpiderç±»ï¼Œé™¤äº†ç»§æ‰¿è¿‡æ¥çš„å±æ€§å¤–ï¼ˆnameã€allow_domainsï¼‰ï¼Œè¿˜æä¾›äº†æ–°çš„å±æ€§å’Œæ–¹æ³•:</span><br></pre></td></tr></table></figure>
<blockquote>
<p>LinkExtractors</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">class scrapy.linkextractors.LinkExtractor</span><br><span class="line"></span><br><span class="line">Link Extractorsçš„ç›®çš„å¾ˆç®€å•:æå–é“¾æ¥ï½¡</span><br><span class="line"></span><br><span class="line">æ¯ä¸ªLinkExtractoræœ‰å”¯ä¸€çš„å…¬å…±æ–¹æ³•æ˜¯extract_links()ï¼Œå®ƒæ¥æ”¶ä¸€ä¸ªResponseå¯¹è±¡ï¼Œå¹¶è¿”å›ä¸€ä¸ªscrapy.link.Linkå¯¹è±¡ã€‚</span><br><span class="line"></span><br><span class="line">Link Extractorsè¦å®ä¾‹åŒ–ä¸€æ¬¡ï¼Œå¹¶ä¸”extract_linksæ–¹æ³•ä¼šæ ¹æ®ä¸åŒçš„responseè°ƒç”¨å¤šæ¬¡æå–é“¾æ¥ï½¡</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">class scrapy.linkextractors.LinkExtractor(</span><br><span class="line">    allow = (),</span><br><span class="line">    deny = (),</span><br><span class="line">    allow_domains = (),</span><br><span class="line">    deny_domains = (),</span><br><span class="line">    deny_extensions = None,</span><br><span class="line">    restrict_xpaths = (),</span><br><span class="line">    tags = (<span class="string">'a'</span>,<span class="string">'area'</span>),</span><br><span class="line">    attrs = (<span class="string">'href'</span>),</span><br><span class="line">    canonicalize = True,</span><br><span class="line">    unique = True,</span><br><span class="line">    process_value = None</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>ä¸»è¦å‚æ•°</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">allowï¼šæ»¡è¶³æ‹¬å·ä¸­<span class="string">"æ­£åˆ™è¡¨è¾¾å¼"</span>çš„å€¼ä¼šè¢«æå–ï¼Œå¦‚æœä¸ºç©ºï¼Œåˆ™å…¨éƒ¨åŒ¹é…</span><br><span class="line"></span><br><span class="line">denyï¼šä¸è¿™ä¸ªæ­£åˆ™è¡¨è¾¾å¼(æˆ–æ­£åˆ™è¡¨è¾¾å¼åˆ—è¡¨)ä¸åŒ¹é…çš„URLä¸€å®šä¸æå–</span><br><span class="line"></span><br><span class="line">allow_domainsï¼šä¼šè¢«æå–çš„é“¾æ¥çš„domains</span><br><span class="line"></span><br><span class="line">deny_domainsï¼šä¸€å®šä¸ä¼šè¢«æå–é“¾æ¥çš„domains</span><br><span class="line"></span><br><span class="line">restrict_xpathsï¼šä½¿ç”¨xpathè¡¨è¾¾å¼ï¼Œå’Œallowå…±åŒä½œç”¨è¿‡æ»¤é“¾æ¥</span><br></pre></td></tr></table></figure>
<blockquote>
<p>rules</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">åœ¨rulesä¸­åŒ…å«ä¸€ä¸ªæˆ–å¤šä¸ªRuleå¯¹è±¡ï¼Œæ¯ä¸ªRuleå¯¹çˆ¬å–ç½‘ç«™çš„åŠ¨ä½œå®šä¹‰äº†ç‰¹å®šæ“ä½œ</span><br><span class="line"></span><br><span class="line">å¦‚æœå¤šä¸ªruleåŒ¹é…äº†ç›¸åŒçš„é“¾æ¥ï¼Œåˆ™æ ¹æ®è§„åˆ™åœ¨æœ¬é›†åˆä¸­è¢«å®šä¹‰çš„é¡ºåºï¼Œç¬¬ä¸€ä¸ªä¼šè¢«ä½¿ç”¨</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">class scrapy.spiders.Rule(</span><br><span class="line">        link_extractor,</span><br><span class="line">        callback = None,</span><br><span class="line">        cb_kwargs = None,</span><br><span class="line">        follow = None,</span><br><span class="line">        process_links = None,</span><br><span class="line">        process_request = None</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">link_extractorï¼šæ˜¯ä¸€ä¸ªLink Extractorå¯¹è±¡ï¼Œç”¨äºå®šä¹‰éœ€è¦æå–çš„é“¾æ¥ã€‚</span><br><span class="line"></span><br><span class="line">callbackï¼šä»link_extractorä¸­æ¯è·å–åˆ°é“¾æ¥æ—¶ï¼Œå‚æ•°æ‰€æŒ‡å®šçš„å€¼ä½œä¸ºå›è°ƒå‡½æ•°ï¼Œè¯¥å›è°ƒå‡½æ•°æ¥å—ä¸€ä¸ªresponseä½œä¸ºå…¶ç¬¬ä¸€ä¸ªå‚æ•°ã€‚</span><br><span class="line"></span><br><span class="line">æ³¨æ„ï¼šå½“ç¼–å†™çˆ¬è™«è§„åˆ™æ—¶ï¼Œé¿å…ä½¿ç”¨parseä½œä¸ºå›è°ƒå‡½æ•°ã€‚</span><br><span class="line">ç”±äºCrawlSpiderä½¿ç”¨parseæ–¹æ³•æ¥å®ç°å…¶é€»è¾‘ï¼Œ</span><br><span class="line">å¦‚æœè¦†ç›–äº†parseæ–¹æ³•ï¼Œcrawl spiderå°†ä¼šè¿è¡Œå¤±è´¥ã€‚</span><br><span class="line"></span><br><span class="line">followï¼šæ˜¯ä¸€ä¸ªå¸ƒå°”(boolean)å€¼ï¼ŒæŒ‡å®šäº†æ ¹æ®è¯¥è§„åˆ™ä»responseæå–çš„é“¾æ¥æ˜¯å¦éœ€è¦è·Ÿè¿›ã€‚ å¦‚æœcallbackä¸ºNoneï¼Œfollowé»˜è®¤è®¾ç½®ä¸ºTrue ï¼Œå¦åˆ™é»˜è®¤ä¸ºFalseã€‚</span><br><span class="line"></span><br><span class="line">process_linksï¼šæŒ‡å®šè¯¥spiderä¸­å“ªä¸ªçš„å‡½æ•°å°†ä¼šè¢«è°ƒç”¨ï¼Œ</span><br><span class="line">ä»link_extractorä¸­è·å–åˆ°é“¾æ¥åˆ—è¡¨æ—¶å°†ä¼šè°ƒç”¨è¯¥å‡½æ•°ï¼Œè¯¥æ–¹æ³•ä¸»è¦ç”¨æ¥è¿‡æ»¤ã€‚</span><br><span class="line"></span><br><span class="line">process_requestï¼šæŒ‡å®šè¯¥spiderä¸­å“ªä¸ªçš„å‡½æ•°å°†ä¼šè¢«è°ƒç”¨ï¼Œ</span><br><span class="line">è¯¥è§„åˆ™æå–åˆ°æ¯ä¸ªrequestæ—¶éƒ½ä¼šè°ƒç”¨è¯¥å‡½æ•°ã€‚(ç”¨æ¥è¿‡æ»¤request)</span><br></pre></td></tr></table></figure>
<h3 id="çˆ¬å–è§„åˆ™-Crawling-rules"><a href="#çˆ¬å–è§„åˆ™-Crawling-rules" class="headerlink" title="çˆ¬å–è§„åˆ™(Crawling rules)"></a>çˆ¬å–è§„åˆ™(Crawling rules)</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ä»¥ä¸Šé¢è·å–è…¾è®¯æ‹›è˜çš„æ•°æ®ä¸ºä¾‹ï¼Œç»™å‡ºé…åˆruleä½¿ç”¨CrawlSpiderçš„ä¾‹å­:</span><br></pre></td></tr></table></figure>
<blockquote>
<p>è¿è¡ŒScrapy shell</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy shell http://hr.tencent.com/position.php?&amp;start=0<span class="comment">#a</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>å¯¼å…¥LinkExtractorï¼Œåˆ›å»ºLinkExtractorå®ä¾‹å¯¹è±¡</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">from scrapy.linkextractors import LinkExtractor</span><br><span class="line"></span><br><span class="line">page_lx = LinkExtractor(allow=(<span class="string">'position.php?&amp;start=\d+'</span>))</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">allow : LinkExtractorå¯¹è±¡æœ€é‡è¦çš„å‚æ•°ä¹‹ä¸€ï¼Œè¿™æ˜¯ä¸€ä¸ªæ­£åˆ™è¡¨è¾¾å¼ï¼Œ</span><br><span class="line">å¿…é¡»è¦åŒ¹é…è¿™ä¸ªæ­£åˆ™è¡¨è¾¾å¼(æˆ–æ­£åˆ™è¡¨è¾¾å¼åˆ—è¡¨)çš„URLæ‰ä¼šè¢«æå–ï¼Œ</span><br><span class="line">å¦‚æœæ²¡æœ‰ç»™å‡º(æˆ–ä¸ºç©º), å®ƒä¼šåŒ¹é…æ‰€æœ‰çš„é“¾æ¥ï½¡</span><br><span class="line"></span><br><span class="line">deny : ç”¨æ³•åŒallowï¼Œåªä¸è¿‡ä¸è¿™ä¸ªæ­£åˆ™è¡¨è¾¾å¼åŒ¹é…çš„URLä¸ä¼šè¢«æå–)ï½¡å®ƒçš„ä¼˜å…ˆçº§é«˜äº allow çš„å‚æ•°ï¼Œå¦‚æœæ²¡æœ‰ç»™å‡º(æˆ–None), å°†ä¸æ’é™¤ä»»ä½•é“¾æ¥ï½¡</span><br></pre></td></tr></table></figure>
<blockquote>
<p>è°ƒç”¨LinkExtractorå®ä¾‹çš„extract_links()æ–¹æ³•æŸ¥è¯¢åŒ¹é…ç»“æœ</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">page_lx.extract_links(response)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>æ²¡æœ‰æŸ¥åˆ°</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[]</span><br></pre></td></tr></table></figure>
<blockquote>
<p>æ³¨æ„è½¬ä¹‰å­—ç¬¦çš„é—®é¢˜ï¼Œç»§ç»­é‡æ–°åŒ¹é…</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">page_lx = LinkExtractor(allow=(<span class="string">'position\.php\?&amp;start=\d+'</span>))</span><br><span class="line">page_lx.extract_links(response)</span><br></pre></td></tr></table></figure>
<p><img src="http://i4.buimg.com/581590/5897238dcd09cd04.png" alt="Markdown"></p>
<h2 id="Pythonå®ç°æ•°æ®è‡ªåŠ¨ç¿»é¡µé‡‡é›†-CrawlSpiderç‰ˆæœ¬"><a href="#Pythonå®ç°æ•°æ®è‡ªåŠ¨ç¿»é¡µé‡‡é›†-CrawlSpiderç‰ˆæœ¬" class="headerlink" title="Pythonå®ç°æ•°æ®è‡ªåŠ¨ç¿»é¡µé‡‡é›†(CrawlSpiderç‰ˆæœ¬)"></a>Pythonå®ç°æ•°æ®è‡ªåŠ¨ç¿»é¡µé‡‡é›†(CrawlSpiderç‰ˆæœ¬)</h2><blockquote>
<p>ç”±äºCrawlSpiderä½¿ç”¨parseæ–¹æ³•æ¥å®ç°å…¶é€»è¾‘ï¼Œå¦‚æœè¦†ç›–äº† parseæ–¹æ³•ï¼Œcrawl spiderå°†ä¼šè¿è¡Œå¤±è´¥ã€‚</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy shellæµ‹è¯•å®Œæˆä¹‹åï¼Œä¿®æ”¹ä»¥ä¸‹ä»£ç </span><br></pre></td></tr></table></figure>
<blockquote>
<p>tencent.py</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">from</span> scrapy.spider <span class="keyword">import</span> CrawlSpider, Rule</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">from</span> tencentspider.items <span class="keyword">import</span> TencentspiderItem</span><br><span class="line"><span class="keyword">from</span> scrapy.linkextractors <span class="keyword">import</span> LinkExtractor</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TencentSpider</span><span class="params">(CrawlSpider)</span>:</span></span><br><span class="line">    name = <span class="string">"tencent"</span></span><br><span class="line">    allowed_domains = [<span class="string">"hr.tencent.com"</span>]</span><br><span class="line">    start_urls = [<span class="string">'http://hr.tencent.com/position.php?&amp;start=0#a'</span>]</span><br><span class="line"></span><br><span class="line">    page_lx = LinkExtractor(allow=(<span class="string">"start=\d+"</span>))</span><br><span class="line"></span><br><span class="line">    rules = [</span><br><span class="line">        Rule(page_lx, callback=<span class="string">"parseContent"</span>, follow=<span class="keyword">True</span>)</span><br><span class="line">    ]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parseContent</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        oddList = response.xpath(<span class="string">'//*[@class="odd"]'</span>)</span><br><span class="line">        evenList = response.xpath(<span class="string">'//*[@class="even"]'</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> odd, even <span class="keyword">in</span> zip(oddList, evenList):</span><br><span class="line">            odditem = TencentspiderItem()</span><br><span class="line">            evenitem = TencentspiderItem()</span><br><span class="line">            odditem[<span class="string">'name'</span>] = odd.xpath(<span class="string">'./td[1]/a/text()'</span>).extract()[<span class="number">0</span>]</span><br><span class="line">            odditem[<span class="string">'detailLink'</span>] = odd.xpath(<span class="string">'.//td[1]/a/@href'</span>).extract()[<span class="number">0</span>]</span><br><span class="line">            odditem[<span class="string">'positionInfo'</span>] = odd.xpath(<span class="string">'./td[2]/text()'</span>).extract()[<span class="number">0</span>]</span><br><span class="line">            odditem[<span class="string">'peopleNumber'</span>] = odd.xpath(<span class="string">'./td[3]/text()'</span>).extract()[<span class="number">0</span>]</span><br><span class="line">            odditem[<span class="string">'workLocation'</span>] = odd.xpath(<span class="string">'./td[4]/text()'</span>).extract()[<span class="number">0</span>]</span><br><span class="line">            odditem[<span class="string">'publicTime'</span>] = odd.xpath(<span class="string">'./td[5]/text()'</span>).extract()[<span class="number">0</span>]</span><br><span class="line">            evenitem[<span class="string">'name'</span>] = even.xpath(<span class="string">'./td[1]/a/text()'</span>).extract()[<span class="number">0</span>]</span><br><span class="line">            evenitem[<span class="string">'detailLink'</span>] = even.xpath(<span class="string">'.//td[1]/a/@href'</span>).extract()[<span class="number">0</span>]</span><br><span class="line">            evenitem[<span class="string">'positionInfo'</span>] = even.xpath(<span class="string">'./td[2]/text()'</span>).extract()[<span class="number">0</span>]</span><br><span class="line">            evenitem[<span class="string">'peopleNumber'</span>] = even.xpath(<span class="string">'./td[3]/text()'</span>).extract()[<span class="number">0</span>]</span><br><span class="line">            evenitem[<span class="string">'workLocation'</span>] = even.xpath(<span class="string">'./td[4]/text()'</span>).extract()[<span class="number">0</span>]</span><br><span class="line">            evenitem[<span class="string">'publicTime'</span>] = even.xpath(<span class="string">'./td[5]/text()'</span>).extract()[<span class="number">0</span>]</span><br><span class="line">            <span class="comment"># å°†è·å–çš„æ•°æ®äº¤ç»™pipeline</span></span><br><span class="line">            <span class="keyword">yield</span> odditem</span><br><span class="line">            <span class="keyword">yield</span> evenitem</span><br></pre></td></tr></table></figure>
<blockquote>
<p>è¿è¡Œscrapy</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy crawl tencent</span><br></pre></td></tr></table></figure>
<p><img src="http://i4.buimg.com/581590/e91ddb214f13049e.png" alt="Markdown"></p>
<h3 id="Logging"><a href="#Logging" class="headerlink" title="Logging"></a>Logging</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Scrapyæä¾›äº†<span class="built_in">log</span>åŠŸèƒ½ï¼Œå¯ä»¥é€šè¿‡loggingæ¨¡å—ä½¿ç”¨</span><br></pre></td></tr></table></figure>
<blockquote>
<p>å¯ä»¥ä¿®æ”¹é…ç½®æ–‡ä»¶settings.pyï¼Œä»»æ„ä½ç½®æ·»åŠ ä¸‹é¢ä¸¤è¡Œï¼Œæ•ˆæœä¼šæ¸…çˆ½å¾ˆå¤šã€‚</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">LOG_FILE = <span class="string">"TencentSpider.log"</span></span><br><span class="line">LOG_LEVEL = <span class="string">"INFO"</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>Log levels</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Scrapyæä¾›5å±‚loggingçº§åˆ«:</span><br><span class="line"></span><br><span class="line">CRITICAL - ä¸¥é‡é”™è¯¯(critical)</span><br><span class="line"></span><br><span class="line">ERROR - ä¸€èˆ¬é”™è¯¯(regular errors)</span><br><span class="line">WARNING - è­¦å‘Šä¿¡æ¯(warning messages)</span><br><span class="line">INFO - ä¸€èˆ¬ä¿¡æ¯(informational messages)</span><br><span class="line">DEBUG - è°ƒè¯•ä¿¡æ¯(debugging messages)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>loggingè®¾ç½®</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">é€šè¿‡åœ¨setting.pyä¸­è¿›è¡Œä»¥ä¸‹è®¾ç½®å¯ä»¥è¢«ç”¨æ¥é…ç½®logging:</span><br><span class="line"></span><br><span class="line">LOG_ENABLED é»˜è®¤: Trueï¼Œå¯ç”¨logging</span><br><span class="line">LOG_ENCODING é»˜è®¤: <span class="string">'utf-8'</span>ï¼Œloggingä½¿ç”¨çš„ç¼–ç </span><br><span class="line">LOG_FILE é»˜è®¤: Noneï¼Œåœ¨å½“å‰ç›®å½•é‡Œåˆ›å»ºloggingè¾“å‡ºæ–‡ä»¶çš„æ–‡ä»¶å</span><br><span class="line">LOG_LEVEL é»˜è®¤: <span class="string">'DEBUG'</span>ï¼Œ<span class="built_in">log</span>çš„æœ€ä½çº§åˆ«</span><br><span class="line">LOG_STDOUT é»˜è®¤: Falseå¦‚æœä¸ºTrueï¼Œè¿›ç¨‹æ‰€æœ‰çš„æ ‡å‡†è¾“å‡º(åŠé”™è¯¯)å°†ä¼šè¢«é‡å®šå‘åˆ°<span class="built_in">log</span>ä¸­ã€‚ä¾‹å¦‚ï¼Œæ‰§è¡Œ<span class="built_in">print</span><span class="string">"hello"</span>ï¼Œå…¶å°†ä¼šåœ¨Scrapy <span class="built_in">log</span>ä¸­æ˜¾ç¤ºã€‚</span><br></pre></td></tr></table></figure>

    </div>
  </div>
  
    <div class="copy-right">
      <div class="markdown-body">
        <blockquote>
        
        
          æœ¬æ–‡ä½œè€… : Matrix <br>
        
        åŸæ–‡é“¾æ¥ : <a href="">http://yoursite.com/2017/04/22/pythonçˆ¬è™«å®ç°è…¾è®¯æ‹›è˜è‡ªåŠ¨ç¿»é¡µé‡‡é›†/</a><br>
        ç‰ˆæƒå£°æ˜ : æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ«å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨ <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜å‡ºå¤„ï¼
        </blockquote>
      </div>
    </div>
  
  
  
    <div class="social-share" style="margin-top: -2rem" data-wechat-qrcode-title="<p>å¾®ä¿¡æ‰«ä¸€æ‰«</p>" data-wechat-qrcode-helper="<p>å¾®ä¿¡å³ä¸Šè§’, æ‰«ä¸€æ‰«åˆ†äº«</p>" data-sites="qzone, qq, weibo, wechat, douban, google, facebook, twitter">
  <span style="color: #6b7487; font-size: 1.4rem;">åˆ†äº«åˆ°: </span>
</div>
<script src="https://cdn.bootcss.com/social-share.js/1.0.16/js/social-share.min.js" async></script>
  

  
    <div id="reward">
  
    <p id="reward-meta">çŸ¥è¯† & æƒ…æ€€ | äºŒè€…å…¼å¾—</p>
  
  <button id="reward-btn">
    
    <span>æŠ•é£Ÿ</span>
  </button>
  <div id="reward-qrcode">
    
      <div class="reward-qrcode--container">
        <img class="qrcode-img" src="/images/wechatpay.jpg" alt="å¾®ä¿¡æ‰«ä¸€æ‰«, å‘æˆ‘æŠ•é£Ÿ">
        <p class="qrcode-meta">å¾®ä¿¡æ‰«ä¸€æ‰«, å‘æˆ‘æŠ•é£Ÿ</p>
      </div>
    
      <div class="reward-qrcode--container">
        <img class="qrcode-img" src="/images/alipaypay.jpg" alt="æ”¯ä»˜å®æ‰«ä¸€æ‰«, å‘æˆ‘æŠ•é£Ÿ">
        <p class="qrcode-meta">æ”¯ä»˜å®æ‰«ä¸€æ‰«, å‘æˆ‘æŠ•é£Ÿ</p>
      </div>
    
  </div>

</div>

<script>
  (() => {
    let button = document.querySelector('#reward-btn'),
      qrcode = document.querySelector('#reward-qrcode'),
      display = false;
    
    button.addEventListener('click', () => {
      qrcode.style.display = display ? 'none' : 'block'
      display = !display
    }, false)
  })()
</script>
  

  <div class="article-footer">
    <div class="article-meta pull-left">
      <span>
        
          <i class="iconfont icon-06tags"></i>æ ‡ç­¾: 
          
          <span class="span--tag">
            <a href="/tags/å¤§æ•°æ®/">
              #å¤§æ•°æ®
            </a>
          </span>
          
          <span class="span--tag">
            <a href="/tags/Python/">
              #Python
            </a>
          </span>
          
        
      </span>
    </div>
    <div class="article-meta pull-right">
    </div>
  </div>
</div>


  <aside id="sidebar">
    <p id="sidebar-header"></p>
    <ol id="sidebar-toc"></ol>
  </aside>
  <script async>setTimeout(generateToc, 10);</script>


  <nav class="post-navigation">
    
      <div class="nav-pre">
        <i class="iconfont icon-prev"></i>
        ä¸Šä¸€ç¯‡:
        <a href="/2017/04/22/Linux Centos7å®‰è£…python3/" target="_self">Linux Centos6.5å®‰è£…python3</a>
      </div>
    
    
      <div class="nav-next">
        ä¸‹ä¸€ç¯‡:
        <a href="/2017/04/22/Pythonå®ç°çˆ¬å–é˜³å…‰çƒ­çº¿é—®æ”¿å¹³å°æ•°æ®/" target="_self">Pythonå®ç°çˆ¬å–é˜³å…‰çƒ­çº¿é—®æ”¿å¹³å°</a>
        <i class="iconfont icon-next"></i>
      </div>
    
  </nav>

  
    <a href="#comment" class="comment-anchor"></a>
<div class="comment-title"><i class="iconfont icon-footprint"></i> ç•™ä¸‹è¶³è¿¹ <i class="iconfont icon-footprint"></i></div>
<div id="vcomments"></div>

<script defer>
  if( true ) {
    let path = getRealPath()
    new Valine({
      el: "#vcomments",
      appId: "Hyq9wkH495DgNHWhDQCOfQSp-gzGzoHsz",
      appKey: "WaR7nrzhliHj9aVwdQzkdlGd",
      notify: false,
      verify: false,
      avatar: "robohash",
      placeholder: "æ­£ç¡®å¡«å†™é‚®ç®±, æ‰èƒ½åŠæ—¶æ”¶åˆ°å›å¤å“¦â™ª(^âˆ‡^*)",
      path
    });
  }
</script>
   

  
    <script defer>
const valineAPI = (() => {
  try {
    AV.init("Hyq9wkH495DgNHWhDQCOfQSp-gzGzoHsz", "WaR7nrzhliHj9aVwdQzkdlGd");
  } catch(error) {}
  const isExist = (identity) => {
    identity = identity || getRealPath();
    let query = new AV.Query('Timer');
    return new Promise((resolve, reject) => {
      query.equalTo("identity", identity);
      query.find().then(results => {
        resolve(results.length > 0);
      }, error => reject(error));
    })
  }

  const _get = (identity) => {
    let query = null;
    if(identity && identity instanceof Array){
      let querys = [];
      for(let i = 0; i < identity.length; ++i) {
        querys[i] = new AV.Query('Timer');
        querys[i].equalTo('identity', identity[i]);
      }
      query = AV.Query.or.apply(null ,querys);
    } else {
      identity = identity || getRealPath();
      query = new AV.Query("Timer");
      query.equalTo("identity", identity);
    }

    return new Promise((resolve, reject) => {
      query.find()
      .then(results => resolve(results))
      .catch(error => reject(error))
    })
  }

  const create = (identity) => {
    identity = identity || getRealPath();
    return new Promise((resolve, reject) => {
      let Todo = AV.Object.extend('Timer');
      let todo = new Todo();
      todo.set("times", 1);
      todo.set("identity", identity);
      todo.save().then(res => resolve(true), error => reject(error));
    })
  }

  const update = (identity) => {
    identity = identity || getRealPath();
    return new Promise((resolve, reject) => {
      let query = new AV.Query('Timer');
      query.equalTo("identity", identity);
      query.find().then(todos => {
        todos.forEach(todo => {
          todo.set("times", todo.attributes.times + 1);
        });
        return AV.Object.saveAll(todos);
      }).then(todos => resolve(true), error => reject(error));
    })
  }

  return {
    isExist,
    _get,
    update,
    create
  }
})()

const calcAndWriteTimes = () => {
  let isPost = true;

  let timerAllDOM = document.querySelectorAll(".article-timer");

  if(isPost) {
    let identity = timerAllDOM[0].getAttribute("data-identity");
    valineAPI.isExist(identity)
    .then(exist => {
      if(exist) {
        return valineAPI.update(identity);
      }
      return new Promise(resolve => resolve(true));
    })
    .then( succuess => valineAPI._get(identity))
    .then( result => timerAllDOM[0].innerText = result[0].attributes.times)
    .catch(error => console.log(error.message))
    return ;
  }

  let timerDOMCache = {};

  for(let timerDOM of timerAllDOM) {
    let identity = timerDOM.getAttribute("data-identity");
    if(timerDOMCache.hasOwnProperty(identity)){
      timerDOMCache[identity].dom.push(timerDOM);
    }else{
      timerDOMCache[identity] = {
        dom: [timerDOM],
        times: undefined
      };
    }
  }

  let identities = Object.keys(timerDOMCache);
  valineAPI._get(identities).then(results => {
    for(let result of results) {
      let {identity, times} = result.attributes;
      timerDOMCache[identity].times = times;
      timerDOMCache[identity].dom.map(item => item.innerText = times);
    }
    for(let identity of identities) {
      if(timerDOMCache[identity].times){
        continue;
      }
      timerDOMCache[identity].dom.map(item => item.innerText = 1);
      valineAPI.create(identity);
    }
  }).catch(error => console.log(error.message))
}

if(true){
  calcAndWriteTimes();
}
</script>
   

</div>


      <footer>
  <p class="site-info">
    åšå®¢å·²èŒèŒå“’è¿è¡Œ<span id="time-to-now"></span><span class="my-face">(â—'â—¡'â—)ï¾‰â™¥</span>
    <br>
    Theme - <a href="https://github.com/dongyuanxin/theme-bmw">BMW</a> | Powered by <a href="https://godbmw.com/">GodBMW</a>
    <br>
    
      Copyright Â© 2019 Matrix
    
  </p>
</footer>



<script>
const timeToNowDOM = document.querySelector("#time-to-now");
const startTimestamp = new Date(2016, 4, 10).getTime();

const updateTimeStr = () => {
  let offset = parseInt(
      (new Date().getTime() - startTimestamp) / 1000,
      10
    ),
    day = Math.floor(offset / 86400),
    hour = Math.floor((offset % 86400) / 3600),
    minute = Math.floor(((offset % 86400) % 3600) / 60),
    second = Math.floor(((offset % 86400) % 3600) % 60);
  timeToNowDOM.innerHTML =
    day + "å¤©" + hour + "å°æ—¶" + minute + "åˆ†é’Ÿ" + second + "ç§’";
  setTimeout(updateTimeStr, 500);
}

setTimeout(updateTimeStr, 500);
</script>


      <div class="back-to-top hidden">
  <span>
    <i class="iconfont icon-60"></i><span></span>%
  </span>
</div>

<script>
const updateIconToTop = percent => {
  let dom = document.querySelector(".back-to-top span span");
  dom.innerText = percent;
  if(percent < 1) {
    document.querySelector(".back-to-top").className = "back-to-top hidden";
  } else {
    document.querySelector(".back-to-top").className = "back-to-top";
  }
}

const handleScoll = () => {
  let isRunning = false;
  return () => {
    if (isRunning) return;
    isRunning = true;
    window.requestAnimationFrame(timestamp => {
      let scrollTop =
          document.documentElement.scrollTop || document.body.scrollTop,
        scrollHeight =
          document.documentElement.scrollHeight ||
          document.body.scrollHeight,
        clientHeight =
          document.documentElement.clientHeight ||
          document.body.clientHeight;
      isRunning = false;
      if (scrollTop <= 1) {
        updateIconToTop(0);
        return;
      }
      if (scrollTop + clientHeight >= scrollHeight) {
        updateIconToTop(100);
      } else {
        updateIconToTop(parseInt(
          100 * scrollTop / (scrollHeight - clientHeight),
          10
        ));
      }
    });
  };
}

const backToTop = () => {
  let scrollTop =
      document.documentElement.scrollTop || document.body.scrollTop,
    delay = 10,
    time = 200;
  if (scrollTop <= 20) {
    document.documentElement.scrollTop = 0;
    document.body.scrollTop = 0;
    return;
  }
  let step = Math.ceil(scrollTop * delay / time);
  let timer = setInterval(() => {
    scrollTop =
      document.documentElement.scrollTop || document.body.scrollTop;
    if (scrollTop - step <= 0) {
      document.documentElement.scrollTop = 0;
      document.body.scrollTop = 0;
      clearInterval(timer);
    } else {
      document.documentElement.scrollTop = scrollTop - step;
      document.body.scrollTop = scrollTop - step;
    }
  }, delay);
}

document.addEventListener("scroll", handleScoll(), false);

document.querySelector(".back-to-top").addEventListener("click", backToTop, false);

</script>

    </div>

    
      <script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script>
<script>
  (() => {
    const mathjaxConfig = {
      showProcessingMessages: false, //å…³é—­jsåŠ è½½è¿‡ç¨‹ä¿¡æ¯
      messageStyle: "none", //ä¸æ˜¾ç¤ºä¿¡æ¯
      jax: ["input/TeX", "output/HTML-CSS"],
      tex2jax: {
        inlineMath: [["$", "$"], ["\\(", "\\)"]], //è¡Œå†…å…¬å¼é€‰æ‹©ç¬¦
        displayMath: [["$$", "$$"], ["\\[", "\\]"]], //æ®µå†…å…¬å¼é€‰æ‹©ç¬¦
        skipTags: ["script", "noscript", "style", "textarea", "pre", "code", "a"] //é¿å¼€æŸäº›æ ‡ç­¾
      },
      "HTML-CSS": {
        availableFonts: ["STIX", "TeX"], //å¯é€‰å­—ä½“
        showMathMenu: false //å…³é—­å³å‡»èœå•æ˜¾ç¤º
      }
    }

    let mathjaxInterval = setInterval(() => {
      if(!window.MathJax){
        return;
      }
      window.MathJax.Hub.Config(mathjaxConfig)
      window.MathJax.Hub.Queue(["Typeset", MathJax.Hub, document.getElementById('app')])

      clearInterval(mathjaxInterval)
    }, 10)    
  })()
</script>
    

    <script src="https://cdn.bootcss.com/fancybox/3.5.2/jquery.fancybox.min.js" async></script>
<script async>
  let fancyTimer = setInterval(function(){
    if(!window.$){
      return;
    }
    $(document).ready(function() {
      $(".post img").each(function () {
        if($(this).parent().get(0).tagName.toLowerCase() === "a") {
          return;
        }
        // $(this).attr("data-fancybox", "gallery"); // if you add 'data-fancybox', img will display after showed
        var element = document.createElement("a");
        $(element).attr("data-fancybox", "gallery");
        $(element).attr("href", $(this).attr("src"));
        $(this).wrap(element);
      });
      
      clearInterval(fancyTimer);
    });
  }, 10);
</script>

    
  </body>

</html>
