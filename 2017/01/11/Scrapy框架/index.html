<!DOCTYPE html>
<html lang="zh-CN">

  
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="utf-8">
  <meta name="author" content="sparsematrix@163.com">
  
  

  <title>Scrapy框架 | 每天，遇到更好的你</title>

  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  
    <meta name="keywords" content="Python爬虫,大数据,Python爬虫,">
  

  <script>
    console.log('\n%c Hexo-theme-bmw v4.0 ' + '%c 🎉 https://github.com/dongyuanxin/theme-bmw 🎉\n' + '\n%c View demo online ' + '%c 🔍 https://godbmw.com/ 🔍  \n' , 'color: #fadfa3; background: #030307; padding:3px 0;', '', 'color: #fadfa3; background: #030307; padding:3px 0;', '');
  </script>

  

  

  
    <link rel="icon" href="/images/favicon.ico">
    <link rel="apple-touch-icon" href="/images/favicon.ico">
  

  <link href="https://cdn.bootcss.com/fancybox/3.5.2/jquery.fancybox.min.css" rel="stylesheet">
  <link rel="stylesheet" href="/css/base.css">
<link rel="stylesheet" href="/icon/iconfont.css">
<link rel="stylesheet" href="/css/github-markdown.css">
<link rel="stylesheet" href="/css/highlight.css">

  <script src="/js/util.js"></script>
<script src="/js/valine.min.js"></script>

  

  
    <link href="https://cdn.bootcss.com/aplayer/1.10.1/APlayer.min.css" rel="stylesheet">
    <script src="https://cdn.bootcss.com/aplayer/1.10.1/APlayer.min.js" async></script>
  

  
    <link href="https://cdn.bootcss.com/social-share.js/1.0.16/css/share.min.css" rel="stylesheet">
  

  <script src="//cdn.bootcss.com/jquery/3.3.1/jquery.min.js" async></script>

  
    <script src="//cdn.jsdelivr.net/npm/leancloud-storage@3.11.0/dist/av-min.js"></script>
  

</head>


  <body>

    

    <div id="app">

      <div class="header-wrap">
  <header>
    <div class="site-brand">
      <div class="site-title">
        <!-- <a href="/">MatrixSparse</a> -->
        <img alt="logo" class="antd-pro-layouts-user-layout-logo" src="/images/favicon.png" style="width: 160px;height: 50px;margin: 5px 0 0 5px;">
      </div>
    </div>
    <nav class="site-navigation">
      <ul class="nav-menu">
      
        <li class="nav-item" data-path="/">
          
            <a href="/" target="_self">
              主页
            </a>
          
        </li>
      
        <li class="nav-item" data-path="/archives/">
          
            <a href="/archives/" target="_self">
              归档
            </a>
          
        </li>
      
        <li class="nav-item" data-path="/categories/">
          
            <a href="/categories/" target="_self">
              分类
            </a>
          
        </li>
      
        <li class="nav-item" data-path="/tags/">
          
            <a href="/tags/" target="_self">
              标签
            </a>
          
        </li>
      
        <li class="nav-item" data-path="">
          
            <a href="javascript:void(0);" v-else="">博客地址</a>
            <ul class="nav-menu--dropdown">
              
                <li>
                  <a href="https://blog.csdn.net/qq_25371579" target="_blank">
                    CSDN
                  </a>
                </li>
              
                <li>
                  <a href="https://github.com/matrixsparse" target="_blank">
                    Github
                  </a>
                </li>
              
                <li>
                  <a href="https://matrixsparse.github.io/" target="_blank">
                    Github Page
                  </a>
                </li>
              
            </ul>
          
        </li>
      
      </ul>
    </nav>
    <i class="iconfont icon-menu"></i>
  </header>
</div>

<script>
  let links = document.querySelectorAll('.nav-item');
  for(let link of links){
    let childrenLink = link.querySelector('ul');
    link.addEventListener('mouseenter', () => {
      if(childrenLink) {
        childrenLink.className = "nav-menu--dropdown active";
      }
    })
    link.addEventListener('mouseleave', () => {
      if(childrenLink) {
        childrenLink.className = "nav-menu--dropdown";
      }
    })
  }
  let rootRealPath = getRealPath(window.location.pathname, true);
  for(let link of links) {
    let linkPath = link.getAttribute("data-path");
    if(linkPath && getRealPath(linkPath, true) === rootRealPath) {
      link.className = "nav-item hover";
    }
  }

  let iconMenu = document.querySelector("i.iconfont.icon-menu"),
    iconMenuClicked = false;
  let navDOM = document.querySelector("nav.site-navigation");
  iconMenu.addEventListener("click", () => {
    iconMenuClicked
      ? navDOM.className = "site-navigation active"
      : navDOM.className = "site-navigation";
    iconMenuClicked = !iconMenuClicked;
  })
</script>


      








<div class="container post-index">

  

<div class="post">
  <h1 class="article-title">
    <span>Scrapy框架</span>
  </h1>
  <div class="article-top-meta">
    <span>
      发布 : 
      2017-01-11
    </span>
    
      <span>
        分类 : 
          <a href="/categories/Python爬虫/">
            Python爬虫
          </a>
      </span>
    
    
      <span>
        浏览 : <span class="article-timer" data-identity="Scrapy框架"></span>
      </span>
    
  </div>

  

  <div class="article-content">
    <div class="markdown-body">
      <h2 id="1-Scrapy框架"><a href="#1-Scrapy框架" class="headerlink" title="1.Scrapy框架"></a>1.Scrapy框架</h2><blockquote>
<p><strong>Scrapy</strong>是用纯Python实现一个为了爬取网站数据、提取结构化数据而编写的应用框架，用途非常广泛。</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">框架的力量，用户只需要定制开发几个模块就可以轻松的实现一个爬虫，</span><br><span class="line">用来抓取网页内容以及各种图片，非常之方便</span><br><span class="line"></span><br><span class="line">Scrapy 使用了 Twisted[<span class="string">'twɪstɪd'</span>](其主要对手是Tornado)异步网络框架来处理网络通讯</span><br><span class="line">可以加快我们的下载速度，不用自己去实现异步框架，并且包含了各种中间件接口</span><br><span class="line">可以灵活的完成各种需求</span><br></pre></td></tr></table></figure>
<p><img src="http://i1.piimg.com/581590/01fd0ed60bdce439.png" alt="Markdown"></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">Scrapy Engine(引擎): 负责Spider、ItemPipeline、Downloader、Scheduler中间的通讯，信号、数据传递等。</span><br><span class="line"></span><br><span class="line">Scheduler(调度器): 它负责接受引擎发送过来的Request请求，并按照一定的方式进行整理排列，入队，当引擎需要时，交还给引擎。</span><br><span class="line"></span><br><span class="line">Downloader（下载器）：负责下载Scrapy Engine(引擎)发送的所有Requests请求，并将其获取到的Responses交还给Scrapy Engine(引擎)，由引擎交给Spider来处理，</span><br><span class="line"></span><br><span class="line">Spider（爬虫）：它负责处理所有Responses,从中分析提取数据，获取Item字段需要的数据，并将需要跟进的URL提交给引擎，再次进入Scheduler(调度器)，</span><br><span class="line"></span><br><span class="line">Item Pipeline(管道)：它负责处理Spider中获取到的Item，并进行进行后期处理（详细分析、过滤、存储等）的地方.</span><br><span class="line"></span><br><span class="line">Downloader Middlewares（下载中间件）：你可以当作是一个可以自定义扩展下载功能的组件。</span><br><span class="line"></span><br><span class="line">Spider Middlewares（Spider中间件）：你可以理解为是一个可以自定扩展和操作引擎和Spider中间通信的功能组件（比如进入Spider的Responses;和从Spider出去的Requests）</span><br></pre></td></tr></table></figure>
<h3 id="1-1-Scrapy的运作流程"><a href="#1-1-Scrapy的运作流程" class="headerlink" title="1.1.Scrapy的运作流程"></a>1.1.Scrapy的运作流程</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">代码写好，程序开始运行...</span><br><span class="line"></span><br><span class="line">引擎：Hi！Spider, 你要处理哪一个网站？</span><br><span class="line"></span><br><span class="line">Spider：老大要我处理xxxx.com。</span><br><span class="line"></span><br><span class="line">引擎：你把第一个需要处理的URL给我吧。</span><br><span class="line"></span><br><span class="line">Spider：给你，第一个URL是xxxxxxx.com。</span><br><span class="line"></span><br><span class="line">引擎：Hi！调度器，我这有request请求你帮我排序入队一下。</span><br><span class="line"></span><br><span class="line">调度器：好的，正在处理你等一下。</span><br><span class="line"></span><br><span class="line">引擎：Hi！调度器，把你处理好的request请求给我。</span><br><span class="line"></span><br><span class="line">调度器：给你，这是我处理好的request</span><br><span class="line"></span><br><span class="line">引擎：Hi！下载器，你按照老大的下载中间件的设置帮我下载一下这个request请求</span><br><span class="line"></span><br><span class="line">下载器：好的！给你，这是下载好的东西。（如果失败：sorry，这个request下载失败了。然后引擎告诉调度器，这个request下载失败了，你记录一下，我们待会儿再下载）</span><br><span class="line"></span><br><span class="line">引擎：Hi！Spider，这是下载好的东西，并且已经按照老大的下载中间件处理过了，你自己处理一下（注意！这儿responses默认是交给def parse()这个函数处理的）</span><br><span class="line"></span><br><span class="line">Spider：（处理完毕数据之后对于需要跟进的URL），Hi！引擎，我这里有两个结果，这个是我需要跟进的URL，还有这个是我获取到的Item数据。</span><br><span class="line"></span><br><span class="line">引擎：Hi ！管道 我这儿有个item你帮我处理一下！调度器！这是需要跟进URL你帮我处理下。然后从第四步开始循环，直到获取完老大需要全部信息。</span><br><span class="line"></span><br><span class="line">管道``调度器：好的，现在就做！</span><br><span class="line"></span><br><span class="line">注意！只有当调度器中不存在任何request了，整个程序才会停止，（也就是说，对于下载失败的URL，Scrapy也会重新下载。）</span><br></pre></td></tr></table></figure>
<h3 id="1-2-编写Scrapy爬虫"><a href="#1-2-编写Scrapy爬虫" class="headerlink" title="1.2.编写Scrapy爬虫"></a>1.2.编写Scrapy爬虫</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">新建项目 (scrapy startproject xxx)：新建一个新的爬虫项目</span><br><span class="line">明确目标 （编写items.py）：明确你想要抓取的目标</span><br><span class="line">制作爬虫 （spiders/xxspider.py）：制作爬虫开始爬取网页</span><br><span class="line">存储内容 （pipelines.py）：设计管道存储爬取内容</span><br></pre></td></tr></table></figure>
<h3 id="1-3-Scrapy-Shell"><a href="#1-3-Scrapy-Shell" class="headerlink" title="1.3.Scrapy Shell"></a>1.3.Scrapy Shell</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Scrapy终端是一个交互终端，我们可以在未启动spider的情况下尝试及调试代码，也可以用来测试XPath或CSS表达式，查看他们的工作方式，方便我们爬取的网页中提取的数据。</span><br><span class="line"></span><br><span class="line">如果安装了 IPython ，Scrapy终端将使用 IPython (替代标准Python终端)。 IPython 终端与其他相比更为强大，提供智能的自动补全，高亮输出，及其他特性。（推荐安装IPython）</span><br></pre></td></tr></table></figure>
<h4 id="1-3-1-selector选择器"><a href="#1-3-1-selector选择器" class="headerlink" title="1.3.1.selector选择器"></a>1.3.1.selector选择器</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Scrapy Selectors 内置 XPath 和 CSS Selector 表达式机制</span><br><span class="line"></span><br><span class="line">Selector有四个基本的方法，最常用的还是xpath:</span><br><span class="line"></span><br><span class="line">xpath(): 传入xpath表达式，返回该表达式所对应的所有节点的selector list列表</span><br><span class="line">extract(): 序列化该节点为Unicode字符串并返回list</span><br><span class="line">css(): 传入CSS表达式，返回该表达式所对应的所有节点的selector list列表，语法同 BeautifulSoup4</span><br><span class="line">re(): 根据传入的正则表达式对数据进行提取，返回Unicode字符串list列表</span><br></pre></td></tr></table></figure>
<blockquote>
<p>以腾讯社招的网站<a href="http://hr.tencent.com/position.php?&amp;start=0#a举例" target="_blank" rel="noopener">http://hr.tencent.com/position.php?&amp;start=0#a举例</a></p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 启动</span></span><br><span class="line">scrapy shell <span class="string">"http://hr.tencent.com/position.php?&amp;start=0#a"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 返回 xpath选择器对象列表</span></span><br><span class="line">response.xpath(<span class="string">'//title'</span>)</span><br><span class="line">[&lt;Selector xpath=<span class="string">'//title'</span> data=u<span class="string">'&lt;title&gt;\u804c\u4f4d\u641c\u7d22 | \u793e\u4f1a\u62db\u8058 | Tencent \u817e\u8baf\u62db\u8058&lt;/title'</span>&gt;]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用 extract()方法返回 Unicode字符串列表</span></span><br><span class="line">response.xpath(<span class="string">'//title'</span>).extract()</span><br><span class="line">[u<span class="string">'&lt;title&gt;\u804c\u4f4d\u641c\u7d22 | \u793e\u4f1a\u62db\u8058 | Tencent \u817e\u8baf\u62db\u8058&lt;/title&gt;'</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打印列表第一个元素，终端编码格式显示</span></span><br><span class="line"><span class="built_in">print</span> response.xpath(<span class="string">'//title'</span>).extract()[0]</span><br><span class="line">&lt;title&gt;职位搜索 | 社会招聘 | Tencent 腾讯招聘&lt;/title&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 返回 xpath选择器对象列表</span></span><br><span class="line">response.xpath(<span class="string">'//title/text()'</span>)</span><br><span class="line">&lt;Selector xpath=<span class="string">'//title/text()'</span> data=u<span class="string">'\u804c\u4f4d\u641c\u7d22 | \u793e\u4f1a\u62db\u8058 | Tencent \u817e\u8baf\u62db\u8058'</span>&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 返回列表第一个元素的Unicode字符串</span></span><br><span class="line">response.xpath(<span class="string">'//title/text()'</span>)[0].extract()</span><br><span class="line">u<span class="string">'\u804c\u4f4d\u641c\u7d22 | \u793e\u4f1a\u62db\u8058 | Tencent \u817e\u8baf\u62db\u8058'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 按终端编码格式显示</span></span><br><span class="line"><span class="built_in">print</span> response.xpath(<span class="string">'//title/text()'</span>)[0].extract()</span><br><span class="line">职位搜索 | 社会招聘 | Tencent 腾讯招聘</span><br><span class="line"></span><br><span class="line">response.xpath(<span class="string">'//*[@class="even"]'</span>)</span><br><span class="line">职位名称:</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> site[0].xpath(<span class="string">'./td[1]/a/text()'</span>).extract()[0]</span><br><span class="line">TEG15-运营开发工程师（深圳）</span><br><span class="line">职位名称详情页:</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> site[0].xpath(<span class="string">'./td[1]/a/@href'</span>).extract()[0]</span><br><span class="line">position_detail.php?id=20744&amp;keywords=&amp;tid=0&amp;lid=0</span><br><span class="line">职位类别:</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> site[0].xpath(<span class="string">'./td[2]/text()'</span>).extract()[0]</span><br><span class="line">技术类</span><br></pre></td></tr></table></figure>
<h2 id="2-新建Scrapy项目"><a href="#2-新建Scrapy项目" class="headerlink" title="2.新建Scrapy项目"></a>2.新建Scrapy项目</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy startproject matrixspider</span><br></pre></td></tr></table></figure>
<p><img src="http://i1.piimg.com/581590/b91d6f2517ea6189.png" alt="Markdown"></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">scrapy.cfg ：项目的配置文件</span><br><span class="line"></span><br><span class="line">matrixspider/ ：项目的Python模块，将会从这里引用代码</span><br><span class="line"></span><br><span class="line">matrixspider/items.py ：项目的目标文件</span><br><span class="line"></span><br><span class="line">matrixspider/pipelines.py ：项目的管道文件</span><br><span class="line"></span><br><span class="line">matrixspider/settings.py ：项目的设置文件</span><br><span class="line"></span><br><span class="line">matrixspider/spiders/ ：存储爬虫代码目录</span><br></pre></td></tr></table></figure>
<h3 id="2-1-明确目标-matrixspider-items-py"><a href="#2-1-明确目标-matrixspider-items-py" class="headerlink" title="2.1.明确目标(matrixspider/items.py)"></a>2.1.明确目标(matrixspider/items.py)</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">我们打算抓取：http://www.datatang.com/data/shopping-mall.html 网站里的所有数据名称、数据图像、数据价格。</span><br><span class="line"></span><br><span class="line">打开matrixspider目录下的items.py</span><br><span class="line"></span><br><span class="line">Item定义结构化数据字段，用来保存爬取到的数据，有点像Python中的dict，但是提供了一些额外的保护减少错误。</span><br><span class="line"></span><br><span class="line">可以通过创建一个scrapy.Item类，并且定义类型为scrapy.Field的类属性来定义一个Item（可以理解成类似于ORM的映射关系）。</span><br><span class="line"></span><br><span class="line">接下来，创建一个MatrixspiderItem类，和构建item模型（model）。</span><br></pre></td></tr></table></figure>
<h4 id="2-1-1-items-py"><a href="#2-1-1-items-py" class="headerlink" title="2.1.1.items.py"></a>2.1.1.items.py</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MatrixspiderItem</span><span class="params">(scrapy.Item)</span>:</span></span><br><span class="line">    name = scrapy.Field()</span><br><span class="line">    author = scrapy.Field()</span><br><span class="line">    hot = scrapy.Field()</span><br><span class="line">    comment = scrapy.Field()</span><br><span class="line">    <span class="keyword">pass</span></span><br></pre></td></tr></table></figure>
<h3 id="2-2-制作爬虫（spiders-matrixspider-py）"><a href="#2-2-制作爬虫（spiders-matrixspider-py）" class="headerlink" title="2.2.制作爬虫（spiders/matrixspider.py）"></a>2.2.制作爬虫（spiders/matrixspider.py）</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">爬虫功能要分两步：</span><br></pre></td></tr></table></figure>
<h4 id="2-2-1-爬数据"><a href="#2-2-1-爬数据" class="headerlink" title="2.2.1.爬数据"></a>2.2.1.爬数据</h4><blockquote>
<p>在当前目录下输入命令，将在matrixspider/spider目录下创建一个名为matrix的爬虫，并指定爬取域的范围：</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy genspider matrix <span class="string">"meishij.net"</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>打开matrixspider/spider目录里的matrix.py，默认增加了下列代码:</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">其实也可以由我们自行创建matrix.py并编写上面的代码，只不过使用命令可以免去编写固定代码的麻烦</span><br><span class="line"></span><br><span class="line">要建立一个Spider，你必须用scrapy.Spider类创建一个子类，并确定了三个强制的属性和一个方法</span><br><span class="line"></span><br><span class="line">name = <span class="string">""</span> ：这个爬虫的识别名称，必须是唯一的，在不同的爬虫必须定义不同的名字</span><br><span class="line"></span><br><span class="line">allow_domains = [] 是搜索的域名范围，也就是爬虫的约束区域，规定爬虫只爬取这个域名下的网页，不存在的URL会被忽略</span><br><span class="line"></span><br><span class="line">start_urls = () ：爬取的URL元祖/列表。爬虫从这里开始抓取数据，所以，第一次下载的数据将会从这些urls开始。其他子URL将会从这些起始URL中继承性生成</span><br><span class="line"></span><br><span class="line">parse(self, response) ：解析的方法，每个初始URL完成下载后将被调用，调用的时候传入从每一个URL传回的Response对象来作为唯一参数，主要作用如下</span><br><span class="line"></span><br><span class="line">负责解析返回的网页数据(response.body)，提取结构化数据(生成item)</span><br><span class="line">生成需要下一页的URL请求</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">from</span> matrixspider.items <span class="keyword">import</span> MatrixspiderItem</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MatrixSpider</span><span class="params">(scrapy.Spider)</span>:</span></span><br><span class="line">    name = <span class="string">"matrix"</span></span><br><span class="line">    allowed_domains = [<span class="string">"meishij.net"</span>]</span><br><span class="line">    start_urls = (</span><br><span class="line">        <span class="string">'http://www.meishij.net/chufang/diy/'</span>,</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        filename = <span class="string">"chufang.html"</span></span><br><span class="line">        open(filename, <span class="string">'w'</span>).write(str(response.body))</span><br></pre></td></tr></table></figure>
<blockquote>
<p>在matrixspider目录下运行</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy crawl matrix</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">matrix是matrixspider类的name属性，也就是使用 scrapy genspider命令的唯一爬虫名。</span><br><span class="line"></span><br><span class="line">运行之后，如果打印的日志出现 [scrapy] INFO: Spider closed (finished)，代表执行完成。</span><br><span class="line">之后当前文件夹中就出现了一个shopping-mall.html文件，里面就是我们刚刚要爬取的网页的全部源代码信息。</span><br></pre></td></tr></table></figure>
<h4 id="2-2-2-取数据"><a href="#2-2-2-取数据" class="headerlink" title="2.2.2.取数据"></a>2.2.2.取数据</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">爬取整个网页完毕，接着就是要取数据了，首先观察页面源码：</span><br></pre></td></tr></table></figure>
<p><img src="http://i4.buimg.com/581590/9c54daae48355c11.png" alt="Markdown"></p>
<blockquote>
<p>使用Scrapy shell测试获取选择器</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy shell http://www.meishij.net/chufang/diy/</span><br></pre></td></tr></table></figure>
<p><img src="http://i4.buimg.com/581590/a59a6da54311b635.png" alt="Markdown"></p>
<blockquote>
<p>matrix.py</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">from</span> matrixspider.items <span class="keyword">import</span> MatrixspiderItem</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MatrixSpider</span><span class="params">(scrapy.Spider)</span>:</span></span><br><span class="line">    name = <span class="string">"matrix"</span></span><br><span class="line">    allowed_domains = [<span class="string">"meishij.net"</span>]</span><br><span class="line">    start_urls = (</span><br><span class="line">        <span class="string">'http://www.meishij.net/chufang/diy/'</span>,</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        items = []</span><br><span class="line">        <span class="keyword">for</span> each <span class="keyword">in</span> response.xpath(<span class="string">'//div[@class="c1"]'</span>):</span><br><span class="line">            item = MatrixspiderItem()</span><br><span class="line">            item[<span class="string">'name'</span>] = each.xpath(<span class="string">'strong/text()'</span>).extract()[<span class="number">0</span>]</span><br><span class="line">            item[<span class="string">'author'</span>] = each.xpath(<span class="string">'em/text()'</span>).extract()[<span class="number">0</span>]</span><br><span class="line">            item[<span class="string">'comment'</span>] = each.xpath(<span class="string">'span/text()'</span>).extract()[<span class="number">0</span>].split(<span class="string">" "</span>)[<span class="number">0</span>]</span><br><span class="line">            item[<span class="string">'hot'</span>] = each.xpath(<span class="string">'span/text()'</span>).extract()[<span class="number">0</span>].split(<span class="string">" "</span>)[<span class="number">3</span>]</span><br><span class="line">            <span class="comment"># xpath返回的是包含一个元素的列表</span></span><br><span class="line">            items.append(item)</span><br><span class="line">            <span class="comment"># 将获取的数据交给pipelines</span></span><br><span class="line">            <span class="comment"># yield item</span></span><br><span class="line">        <span class="comment"># 返回数据，不经过pipeline</span></span><br><span class="line">        <span class="keyword">return</span> items</span><br></pre></td></tr></table></figure>
<blockquote>
<p>在matrixspider目录下运行</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy crawl matrix</span><br></pre></td></tr></table></figure>
<p><img src="http://i4.buimg.com/581590/42899eb46d955fc5.png" alt="Markdown"></p>
<h3 id="2-3-保存数据"><a href="#2-3-保存数据" class="headerlink" title="2.3.保存数据"></a>2.3.保存数据</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># json格式，默认为Unicode编码</span></span><br><span class="line">scrapy crawl matrix -o chufang.json</span><br><span class="line"></span><br><span class="line"><span class="comment"># json lines格式，默认为Unicode编码</span></span><br><span class="line">scrapy crawl matrix -o chufang.jsonl</span><br><span class="line"></span><br><span class="line"><span class="comment"># csv 逗号表达式，可用Excel打开</span></span><br><span class="line">scrapy crawl matrix -o chufang.csv</span><br><span class="line"></span><br><span class="line"><span class="comment"># xml格式</span></span><br><span class="line">scrapy crawl matrix -o chufang.xml</span><br></pre></td></tr></table></figure>
<p><img src="http://i4.buimg.com/581590/89ccb9575a81a9d1.png" alt="Markdown"></p>
<p><img src="http://i4.buimg.com/581590/9b52cbc9683c7c39.png" alt="Markdown"></p>
<h3 id="2-4-Item-Pipeline"><a href="#2-4-Item-Pipeline" class="headerlink" title="2.4.Item Pipeline"></a>2.4.Item Pipeline</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">当Item在Spider中被收集之后，它将会被传递到Item Pipeline，这些Item Pipeline组件按定义的顺序处理Item。</span><br><span class="line"></span><br><span class="line">每个Item Pipeline都是实现了简单方法的Python类，比如决定此Item是丢弃而存储。以下是item pipeline的一些典型应用：</span><br><span class="line"></span><br><span class="line">验证爬取的数据(检查item包含某些字段，比如说name字段)</span><br><span class="line">查重(并丢弃)</span><br><span class="line">将爬取结果保存到文件或者数据库中</span><br></pre></td></tr></table></figure>
<blockquote>
<p>编写item pipeline</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">编写item pipeline很简单，item pipiline组件是一个独立的Python类，其中process_item()方法必须实现:</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> something</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SomethingPipeline</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span>    </span><br><span class="line">        <span class="comment"># 可选实现，做参数初始化等</span></span><br><span class="line">        <span class="comment"># doing something</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span><span class="params">(self, item, spider)</span>:</span></span><br><span class="line">        <span class="comment"># item (Item 对象) – 被爬取的item</span></span><br><span class="line">        <span class="comment"># spider (Spider 对象) – 爬取该item的spider</span></span><br><span class="line">        <span class="comment"># 这个方法必须实现，每个item pipeline组件都需要调用该方法，</span></span><br><span class="line">        <span class="comment"># 这个方法必须返回一个 Item 对象，被丢弃的item将不会被之后的pipeline组件所处理。</span></span><br><span class="line">        <span class="keyword">return</span> item</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">open_spider</span><span class="params">(self, spider)</span>:</span></span><br><span class="line">        <span class="comment"># spider (Spider 对象) – 被开启的spider</span></span><br><span class="line">        <span class="comment"># 可选实现，当spider被开启时，这个方法被调用。</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">close_spider</span><span class="params">(self, spider)</span>:</span></span><br><span class="line">        <span class="comment"># spider (Spider 对象) – 被关闭的spider</span></span><br><span class="line">        <span class="comment"># 可选实现，当spider被关闭时，这个方法被调用</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>item写入JSON文件</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">以下pipeline将所有(从所有<span class="string">'spider'</span>中)爬取到的item，存储到一个独立地items.json 文件，</span><br><span class="line">每行包含一个序列化为<span class="string">'JSON'</span>格式的<span class="string">'item'</span>:</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Define your item pipelines here</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Don't forget to add your pipeline to the ITEM_PIPELINES setting</span></span><br><span class="line"><span class="comment"># See: http://doc.scrapy.org/en/latest/topics/item-pipeline.html</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MatrixspiderPipeline</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.file = open(<span class="string">'menu.json'</span>, <span class="string">'wb'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span><span class="params">(self, item, spider)</span>:</span></span><br><span class="line">        content = json.dumps(dict(item), ensure_ascii=<span class="keyword">False</span>) + <span class="string">"\n"</span></span><br><span class="line">        self.file.write(bytes(content,encoding=<span class="string">'utf-8'</span>))</span><br><span class="line">        <span class="keyword">return</span> item</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">close_spider</span><span class="params">(self, spider)</span>:</span></span><br><span class="line">        self.file.close()</span><br></pre></td></tr></table></figure>
<blockquote>
<p>启用一个Item Pipeline组件</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">为了启用Item Pipeline组件</span><br><span class="line"></span><br><span class="line">必须将它的类添加到settings.py文件ITEM_PIPELINES配置，就像下面这个例子:</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ITEM_PIPELINES = &#123;</span><br><span class="line">   <span class="string">'matrixspider.pipelines.MatrixspiderPipeline'</span>: <span class="number">300</span>,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><img src="http://i4.buimg.com/581590/66d74f5e4d76dc5c.png" alt="Markdown"></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">分配给每个类的整型值，确定了他们运行的顺序，item按数字从低到高的顺序，</span><br><span class="line">通过pipeline，通常将这些数字定义在0-1000范围内（0-1000随意设置，数值越低，组件的优先级越高）</span><br></pre></td></tr></table></figure>
<blockquote>
<p>重新启动爬虫</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy crawl matrix</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">查看当前目录是否生成menu.json</span><br></pre></td></tr></table></figure>
<p><img src="http://i4.buimg.com/581590/24d6bdb782062d4d.png" alt="Markdown"></p>

    </div>
  </div>
  
    <div class="copy-right">
      <div class="markdown-body">
        <blockquote>
        
        
          本文作者 : Matrix <br>
        
        原文链接 : <a href="">https://matrixsparse.github.io/2017/01/11/Scrapy框架/</a><br>
        版权声明 : 本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> 许可协议。转载请注明出处！
        </blockquote>
      </div>
    </div>
  
  
  
    <div class="social-share" style="margin-top: -2rem" data-wechat-qrcode-title="<p>微信扫一扫</p>" data-wechat-qrcode-helper="<p>微信右上角, 扫一扫分享</p>" data-sites="qzone, qq, weibo, wechat, douban, google, facebook, twitter">
  <span style="color: #6b7487; font-size: 1.4rem;">分享到: </span>
</div>
<script src="https://cdn.bootcss.com/social-share.js/1.0.16/js/social-share.min.js" async></script>
  

  
    <div id="reward">
  
    <p id="reward-meta">知识 & 情怀 | 二者兼得</p>
  
  <button id="reward-btn">
    
    <span>投食</span>
  </button>
  <div id="reward-qrcode">
    
      <div class="reward-qrcode--container">
        <img class="qrcode-img" src="/images/wechatpay.jpg" alt="微信扫一扫, 向我投食">
        <p class="qrcode-meta">微信扫一扫, 向我投食</p>
      </div>
    
      <div class="reward-qrcode--container">
        <img class="qrcode-img" src="/images/alipaypay.jpg" alt="支付宝扫一扫, 向我投食">
        <p class="qrcode-meta">支付宝扫一扫, 向我投食</p>
      </div>
    
  </div>

</div>

<script>
  (() => {
    let button = document.querySelector('#reward-btn'),
      qrcode = document.querySelector('#reward-qrcode'),
      display = false;
    
    button.addEventListener('click', () => {
      qrcode.style.display = display ? 'none' : 'block'
      display = !display
    }, false)
  })()
</script>
  

  <div class="article-footer">
    <div class="article-meta pull-left">
      <span>
        
          <i class="iconfont icon-06tags"></i>标签: 
          
          <span class="span--tag">
            <a href="/tags/大数据/">
              #大数据
            </a>
          </span>
          
          <span class="span--tag">
            <a href="/tags/Python爬虫/">
              #Python爬虫
            </a>
          </span>
          
        
      </span>
    </div>
    <div class="article-meta pull-right">
    </div>
  </div>
</div>


  <aside id="sidebar">
    <p id="sidebar-header"></p>
    <ol id="sidebar-toc"></ol>
  </aside>
  <script async>setTimeout(generateToc, 10);</script>


  <nav class="post-navigation">
    
      <div class="nav-pre">
        <i class="iconfont icon-prev"></i>
        上一篇:
        <a href="/2017/01/11/爬虫原理与数据抓取/" target="_self">爬虫原理与数据抓取</a>
      </div>
    
    
      <div class="nav-next">
        下一篇:
        <a href="/2017/01/12/Spark 2.0介绍：Dataset介绍和使用/" target="_self">Spark 2.0介绍：Dataset介绍和使用</a>
        <i class="iconfont icon-next"></i>
      </div>
    
  </nav>

  
    <a href="#comment" class="comment-anchor"></a>
<div class="comment-title"><i class="iconfont icon-footprint"></i> 留下足迹 <i class="iconfont icon-footprint"></i></div>
<div id="vcomments"></div>

<script defer>
  if( true ) {
    let path = getRealPath()
    new Valine({
      el: "#vcomments",
      appId: "Hyq9wkH495DgNHWhDQCOfQSp-gzGzoHsz",
      appKey: "WaR7nrzhliHj9aVwdQzkdlGd",
      notify: false,
      verify: false,
      avatar: "robohash",
      placeholder: "正确填写邮箱, 才能及时收到回复哦♪(^∇^*)",
      path
    });
  }
</script>
   

  
    <script defer>
const valineAPI = (() => {
  try {
    AV.init("Hyq9wkH495DgNHWhDQCOfQSp-gzGzoHsz", "WaR7nrzhliHj9aVwdQzkdlGd");
  } catch(error) {}
  const isExist = (identity) => {
    identity = identity || getRealPath();
    let query = new AV.Query('Timer');
    return new Promise((resolve, reject) => {
      query.equalTo("identity", identity);
      query.find().then(results => {
        resolve(results.length > 0);
      }, error => reject(error));
    })
  }

  const _get = (identity) => {
    let query = null;
    if(identity && identity instanceof Array){
      let querys = [];
      for(let i = 0; i < identity.length; ++i) {
        querys[i] = new AV.Query('Timer');
        querys[i].equalTo('identity', identity[i]);
      }
      query = AV.Query.or.apply(null ,querys);
    } else {
      identity = identity || getRealPath();
      query = new AV.Query("Timer");
      query.equalTo("identity", identity);
    }

    return new Promise((resolve, reject) => {
      query.find()
      .then(results => resolve(results))
      .catch(error => reject(error))
    })
  }

  const create = (identity) => {
    identity = identity || getRealPath();
    return new Promise((resolve, reject) => {
      let Todo = AV.Object.extend('Timer');
      let todo = new Todo();
      todo.set("times", 1);
      todo.set("identity", identity);
      todo.save().then(res => resolve(true), error => reject(error));
    })
  }

  const update = (identity) => {
    identity = identity || getRealPath();
    return new Promise((resolve, reject) => {
      let query = new AV.Query('Timer');
      query.equalTo("identity", identity);
      query.find().then(todos => {
        todos.forEach(todo => {
          todo.set("times", todo.attributes.times + 1);
        });
        return AV.Object.saveAll(todos);
      }).then(todos => resolve(true), error => reject(error));
    })
  }

  return {
    isExist,
    _get,
    update,
    create
  }
})()

const calcAndWriteTimes = () => {
  let isPost = true;

  let timerAllDOM = document.querySelectorAll(".article-timer");

  if(isPost) {
    let identity = timerAllDOM[0].getAttribute("data-identity");
    valineAPI.isExist(identity)
    .then(exist => {
      if(exist) {
        return valineAPI.update(identity);
      }
      return new Promise(resolve => resolve(true));
    })
    .then( succuess => valineAPI._get(identity))
    .then( result => timerAllDOM[0].innerText = result[0].attributes.times)
    .catch(error => console.log(error.message))
    return ;
  }

  let timerDOMCache = {};

  for(let timerDOM of timerAllDOM) {
    let identity = timerDOM.getAttribute("data-identity");
    if(timerDOMCache.hasOwnProperty(identity)){
      timerDOMCache[identity].dom.push(timerDOM);
    }else{
      timerDOMCache[identity] = {
        dom: [timerDOM],
        times: undefined
      };
    }
  }

  let identities = Object.keys(timerDOMCache);
  valineAPI._get(identities).then(results => {
    for(let result of results) {
      let {identity, times} = result.attributes;
      timerDOMCache[identity].times = times;
      timerDOMCache[identity].dom.map(item => item.innerText = times);
    }
    for(let identity of identities) {
      if(timerDOMCache[identity].times){
        continue;
      }
      timerDOMCache[identity].dom.map(item => item.innerText = 1);
      valineAPI.create(identity);
    }
  }).catch(error => console.log(error.message))
}

if(true){
  calcAndWriteTimes();
}
</script>
   

</div>


      <footer>
  <p class="site-info">
    博客已萌萌哒运行<span id="time-to-now"></span><span class="my-face">(●'◡'●)ﾉ♥</span>
    <br>
    Theme - <a href="https://github.com/dongyuanxin/theme-bmw">BMW</a> | Powered by <a href="https://godbmw.com/">GodBMW</a>
    <br>
    
      Copyright © 2019 Matrix
    
  </p>
</footer>



<script>
const timeToNowDOM = document.querySelector("#time-to-now");
const startTimestamp = new Date(2016, 4, 10).getTime();

const updateTimeStr = () => {
  let offset = parseInt(
      (new Date().getTime() - startTimestamp) / 1000,
      10
    ),
    day = Math.floor(offset / 86400),
    hour = Math.floor((offset % 86400) / 3600),
    minute = Math.floor(((offset % 86400) % 3600) / 60),
    second = Math.floor(((offset % 86400) % 3600) % 60);
  timeToNowDOM.innerHTML =
    day + "天" + hour + "小时" + minute + "分钟" + second + "秒";
  setTimeout(updateTimeStr, 500);
}

setTimeout(updateTimeStr, 500);
</script>


      <div class="back-to-top hidden">
  <span>
    <i class="iconfont icon-60"></i><span></span>%
  </span>
</div>

<script>
const updateIconToTop = percent => {
  let dom = document.querySelector(".back-to-top span span");
  dom.innerText = percent;
  if(percent < 1) {
    document.querySelector(".back-to-top").className = "back-to-top hidden";
  } else {
    document.querySelector(".back-to-top").className = "back-to-top";
  }
}

const handleScoll = () => {
  let isRunning = false;
  return () => {
    if (isRunning) return;
    isRunning = true;
    window.requestAnimationFrame(timestamp => {
      let scrollTop =
          document.documentElement.scrollTop || document.body.scrollTop,
        scrollHeight =
          document.documentElement.scrollHeight ||
          document.body.scrollHeight,
        clientHeight =
          document.documentElement.clientHeight ||
          document.body.clientHeight;
      isRunning = false;
      if (scrollTop <= 1) {
        updateIconToTop(0);
        return;
      }
      if (scrollTop + clientHeight >= scrollHeight) {
        updateIconToTop(100);
      } else {
        updateIconToTop(parseInt(
          100 * scrollTop / (scrollHeight - clientHeight),
          10
        ));
      }
    });
  };
}

const backToTop = () => {
  let scrollTop =
      document.documentElement.scrollTop || document.body.scrollTop,
    delay = 10,
    time = 200;
  if (scrollTop <= 20) {
    document.documentElement.scrollTop = 0;
    document.body.scrollTop = 0;
    return;
  }
  let step = Math.ceil(scrollTop * delay / time);
  let timer = setInterval(() => {
    scrollTop =
      document.documentElement.scrollTop || document.body.scrollTop;
    if (scrollTop - step <= 0) {
      document.documentElement.scrollTop = 0;
      document.body.scrollTop = 0;
      clearInterval(timer);
    } else {
      document.documentElement.scrollTop = scrollTop - step;
      document.body.scrollTop = scrollTop - step;
    }
  }, delay);
}

document.addEventListener("scroll", handleScoll(), false);

document.querySelector(".back-to-top").addEventListener("click", backToTop, false);

</script>

    </div>

    
      <script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script>
<script>
  (() => {
    const mathjaxConfig = {
      showProcessingMessages: false, //关闭js加载过程信息
      messageStyle: "none", //不显示信息
      jax: ["input/TeX", "output/HTML-CSS"],
      tex2jax: {
        inlineMath: [["$", "$"], ["\\(", "\\)"]], //行内公式选择符
        displayMath: [["$$", "$$"], ["\\[", "\\]"]], //段内公式选择符
        skipTags: ["script", "noscript", "style", "textarea", "pre", "code", "a"] //避开某些标签
      },
      "HTML-CSS": {
        availableFonts: ["STIX", "TeX"], //可选字体
        showMathMenu: false //关闭右击菜单显示
      }
    }

    let mathjaxInterval = setInterval(() => {
      if(!window.MathJax){
        return;
      }
      window.MathJax.Hub.Config(mathjaxConfig)
      window.MathJax.Hub.Queue(["Typeset", MathJax.Hub, document.getElementById('app')])

      clearInterval(mathjaxInterval)
    }, 10)    
  })()
</script>
    

    <script src="https://cdn.bootcss.com/fancybox/3.5.2/jquery.fancybox.min.js" async></script>
<script async>
  let fancyTimer = setInterval(function(){
    if(!window.$){
      return;
    }
    $(document).ready(function() {
      $(".post img").each(function () {
        if($(this).parent().get(0).tagName.toLowerCase() === "a") {
          return;
        }
        // $(this).attr("data-fancybox", "gallery"); // if you add 'data-fancybox', img will display after showed
        var element = document.createElement("a");
        $(element).attr("data-fancybox", "gallery");
        $(element).attr("href", $(this).attr("src"));
        $(this).wrap(element);
      });
      
      clearInterval(fancyTimer);
    });
  }, 10);
</script>

    
  </body>

</html>
